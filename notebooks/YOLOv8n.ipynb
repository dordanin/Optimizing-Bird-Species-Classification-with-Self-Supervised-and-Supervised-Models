{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5655,
     "status": "ok",
     "timestamp": 1722438208361,
     "user": {
      "displayName": "דור דנינו",
      "userId": "17259148283236873173"
     },
     "user_tz": -180
    },
    "id": "dD916Btcr3Sl",
    "outputId": "171236cb-5be3-4f57-bf99-23c52c9aad36"
   },
   "source": [
    "# Notebook for YOLOv8n-cls models without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5655,
     "status": "ok",
     "timestamp": 1722438208361,
     "user": {
      "displayName": "דור דנינו",
      "userId": "17259148283236873173"
     },
     "user_tz": -180
    },
    "id": "dD916Btcr3Sl",
    "outputId": "171236cb-5be3-4f57-bf99-23c52c9aad36"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set of models with the following parameters:\n",
    "1. Automatic mixed precision\n",
    "2. Batch size of 32\n",
    "4. No augmentations\n",
    "5. 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErBvqpBYr9Yf",
    "outputId": "0b02831e-e56e-472b-b67a-8b9b7dfdad54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=SGD_noAug, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\SGD_noAug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\SGD_noAug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.413G      4.869         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 42.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.675       0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      0.47G      1.215         27        224: 100%|██████████| 2645/2645 [01:10<00:00, 37.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.895      0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.447G     0.5566         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.455G     0.3602         27        224: 100%|██████████| 2645/2645 [01:04<00:00, 40.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.954      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.447G     0.2068         27        224: 100%|██████████| 2645/2645 [01:04<00:00, 41.01it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.963      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.455G     0.1239         27        224: 100%|██████████| 2645/2645 [01:04<00:00, 41.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.965      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.447G    0.07341         27        224: 100%|██████████| 2645/2645 [01:04<00:00, 40.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.966      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.455G    0.04754         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.447G    0.03203         27        224: 100%|██████████| 2645/2645 [01:04<00:00, 40.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.455G    0.02631         27        224: 100%|██████████| 2645/2645 [01:04<00:00, 41.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.193 hours.\n",
      "Optimizer stripped from runs\\classify\\SGD_noAug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\SGD_noAug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\SGD_noAug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.967      0.996\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_noAug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_noAug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C80C9A9DF0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.981714278459549\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9672380685806274, 'metrics/accuracy_top5': 0.9961904883384705, 'fitness': 0.981714278459549}\n",
       "save_dir: WindowsPath('runs/classify/SGD_noAug')\n",
       "speed: {'preprocess': 0.07313619341169085, 'inference': 0.1344652630033947, 'loss': 0.0003808339436848958, 'postprocess': 0.0003809247698102678}\n",
       "task: 'classify'\n",
       "top1: 0.9672380685806274\n",
       "top5: 0.9961904883384705"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with SGD optimizer and no augmentations\n",
    "mymodel_SGD_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_SGD_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='SGD',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='SGD_noAug',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "error",
     "timestamp": 1722429687601,
     "user": {
      "displayName": "דור דנינו",
      "userId": "17259148283236873173"
     },
     "user_tz": -180
    },
    "id": "q_BqhL_5sCXf",
    "outputId": "f91a0446-c12f-417b-f699-c1b630d13030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 66.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.996\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_noAug2\u001b[0m\n",
      "Top1 accuracy is 0.9676 and Top5 accuracy is 0.9962\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_SGD_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=Adam_noAug, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\Adam_noAug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 28/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\Adam_noAug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.417G      1.825         27        224: 100%|██████████| 2645/2645 [01:20<00:00, 32.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 48.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.542      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      0.44G        1.8         27        224: 100%|██████████| 2645/2645 [01:13<00:00, 35.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.774      0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.417G      1.465         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.799      0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.419G      1.342         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 48.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.85      0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.417G       1.17         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.886      0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.417G       1.01         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.66it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.905       0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.417G     0.8557         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.419G     0.7047         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.934      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.417G     0.5314         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.941       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.419G     0.3595         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.61it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 48.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.945      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.204 hours.\n",
      "Optimizer stripped from runs\\classify\\Adam_noAug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\Adam_noAug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\Adam_noAug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.945      0.992\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_noAug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_noAug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C8111AACD0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9683809578418732\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9451428651809692, 'metrics/accuracy_top5': 0.9916190505027771, 'fitness': 0.9683809578418732}\n",
       "save_dir: WindowsPath('runs/classify/Adam_noAug')\n",
       "speed: {'preprocess': 0.06590298243931361, 'inference': 0.14705558050246467, 'loss': 0.000381288074311756, 'postprocess': 0.0003807431175595238}\n",
       "task: 'classify'\n",
       "top1: 0.9451428651809692\n",
       "top5: 0.9916190505027771"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with Adam optimizer and no augmentations\n",
    "mymodel_Adam_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_Adam_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='Adam',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='Adam_noAug',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 57.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.945      0.992\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_noAug2\u001b[0m\n",
      "Top1 accuracy is 0.9451 and Top5 accuracy is 0.9916\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_Adam_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.78 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=AdamW_noAug, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\AdamW_noAug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\AdamW_noAug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.413G      2.025         27        224: 100%|██████████| 2645/2645 [01:22<00:00, 32.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.742      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.447G     0.9701         27        224: 100%|██████████| 2645/2645 [01:12<00:00, 36.40it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.877      0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.447G      0.639         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.58it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.913      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.463G     0.4386         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.10it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.939      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.447G     0.2777         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.948      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.463G     0.1722         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 48.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.958      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.447G      0.102         27        224: 100%|██████████| 2645/2645 [01:02<00:00, 42.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.962      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.463G    0.05333         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 40.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.96      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.447G    0.02066         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.964      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.463G   0.007198         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.202 hours.\n",
      "Optimizer stripped from runs\\classify\\AdamW_noAug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\AdamW_noAug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\AdamW_noAug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.994\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_noAug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_noAug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022409C47F40>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.981333315372467\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9683809280395508, 'metrics/accuracy_top5': 0.9942857027053833, 'fitness': 0.981333315372467}\n",
       "save_dir: WindowsPath('runs/classify/AdamW_noAug')\n",
       "speed: {'preprocess': 0.07047153654552642, 'inference': 0.13409423828125, 'loss': 0.0015241532098679315, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9683809280395508\n",
       "top5: 0.9942857027053833"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with AdamW optimizer and no augmentations\n",
    "mymodel_AdamW_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_AdamW_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='AdamW',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='AdamW_noAug',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 38.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.995\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_noAug2\u001b[0m\n",
      "Top1 accuracy is 0.9684 and Top5 accuracy is 0.9947\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_AdamW_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSprop_noAug, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSprop_noAug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 28/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSprop_noAug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.424G      7.793         27        224: 100%|██████████| 2645/2645 [01:14<00:00, 35.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all   0.000762     0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.459G      6.103         27        224: 100%|██████████| 2645/2645 [01:13<00:00, 36.07it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.459G      5.663         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00229     0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.466G      5.397         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 40.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 49.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00686      0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.459G      5.336         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 48.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00686      0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.466G      5.217         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00495     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.459G      5.112         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00533     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.468G      4.995         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 40.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00419     0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.459G       4.85         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.10it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00495     0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.468G       4.64         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00533     0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.200 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSprop_noAug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00533      0.032\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C807C9D730>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.01866666739806533\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.005333333276212215, 'metrics/accuracy_top5': 0.03200000151991844, 'fitness': 0.01866666739806533}\n",
       "save_dir: WindowsPath('runs/classify/RMSprop_noAug')\n",
       "speed: {'preprocess': 0.06724439348493304, 'inference': 0.14018521990094865, 'loss': 0.0007619403657459077, 'postprocess': 0.0003808339436848958}\n",
       "task: 'classify'\n",
       "top1: 0.005333333276212215\n",
       "top5: 0.03200000151991844"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and no augmentations(starting learning rate = 0.01)\n",
    "mymodel_RMSprop_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_RMSprop_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSprop_noAug'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSprop_noAug_v2, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.001, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSprop_noAug_v2\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 158/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.001, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSprop_noAug_v2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.424G      4.958         27        224: 100%|██████████| 2645/2645 [01:13<00:00, 36.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00419     0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.459G      4.769         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00952     0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.459G      4.333         27        224: 100%|██████████| 2645/2645 [01:03<00:00, 41.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 50.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0156     0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.468G      3.976         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0126      0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.457G      3.722         27        224: 100%|██████████| 2645/2645 [01:00<00:00, 43.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.016     0.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.468G      3.496         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.10it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0118     0.0556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.459G      3.313         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.40it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0171      0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.468G      3.155         27        224: 100%|██████████| 2645/2645 [01:02<00:00, 42.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0171      0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.459G      2.985         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0183     0.0655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.468G      2.824         27        224: 100%|██████████| 2645/2645 [01:06<00:00, 39.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0171     0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.194 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_v2\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_v2\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSprop_noAug_v2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0183     0.0659\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_v2\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C83C286640>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.04209523648023605\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.018285714089870453, 'metrics/accuracy_top5': 0.06590475887060165, 'fitness': 0.04209523648023605}\n",
       "save_dir: WindowsPath('runs/classify/RMSprop_noAug_v2')\n",
       "speed: {'preprocess': 0.06421715872628349, 'inference': 0.14135487874348956, 'loss': 0.0003810155959356399, 'postprocess': 0.00038165137881324406}\n",
       "task: 'classify'\n",
       "top1: 0.018285714089870453\n",
       "top5: 0.06590475887060165"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and no augmentations(starting learning rate = 0.001)\n",
    "mymodel_RMSprop_noAug_v2 = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_RMSprop_noAug_v2.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    lr0=0.001,\n",
    "    lrf=0.001,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSprop_noAug_v2'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.70  Python-3.8.18 torch-2.2.2 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 77.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.032      0.103\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train43342\u001b[0m\n",
      "Top1 accuracy is 0.0320 and Top5 accuracy is 0.1032\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RMSprop_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.76 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSprop_noAug_v32, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.008, lrf=0.005, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSprop_noAug_v32\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.008, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSprop_noAug_v32\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.417G      5.151         27        224: 100%|██████████| 2645/2645 [01:18<00:00, 33.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.463G      4.574         27        224: 100%|██████████| 2645/2645 [01:12<00:00, 36.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00343     0.0217\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.463G      4.422         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.013     0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.466G      4.689         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.132      0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.463G      4.536         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.202       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.482G      4.318         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.10it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.263      0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.463G      4.098         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.19it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.326      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.466G      3.865         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.362      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.461G      3.554         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.402      0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.482G       3.14         27        224: 100%|██████████| 2645/2645 [01:05<00:00, 40.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.437      0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.199 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_v32\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_v32\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSprop_noAug_v32\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.437      0.701\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_v32\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_v32\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C0D6DEDF70>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.5691428780555725\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.437333345413208, 'metrics/accuracy_top5': 0.700952410697937, 'fitness': 0.5691428780555725}\n",
       "save_dir: WindowsPath('runs/classify/RMSprop_noAug_v32')\n",
       "speed: {'preprocess': 0.06438037327357701, 'inference': 0.13200342087518602, 'loss': 0.0, 'postprocess': 0.002453031994047619}\n",
       "task: 'classify'\n",
       "top1: 0.437333345413208\n",
       "top5: 0.700952410697937"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and no augmentations(starting learning rate = 0.008, final learning rate = 0.005)\n",
    "mymodel_RMSprop_noAug_v3 = YOLO(\"yolov8n-cls.pt\").to(device)\n",
    "mymodel_RMSprop_noAug_v3.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    lr0=0.008,\n",
    "    lrf=0.005,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSprop_noAug_v3'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mymodel_RMSprop_noAug_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.70  Python-3.8.18 torch-2.2.2 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 77.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.032      0.103\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train43342\u001b[0m\n",
      "Top1 accuracy is 0.0320 and Top5 accuracy is 0.1032\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RMSprop_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=20, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSprop_noAug_v52, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.001, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSprop_noAug_v52\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSprop_noAug_v52\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20     0.417G      5.204         27        224: 100%|██████████| 2645/2645 [00:42<00:00, 61.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019     0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      0.48G      4.844         27        224: 100%|██████████| 2645/2645 [00:40<00:00, 65.22it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 63.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00495     0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20     0.457G      4.877         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 62.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0301      0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20     0.466G      5.378         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 63.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0503      0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20     0.457G      5.351         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 70.51it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0571      0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20     0.463G      5.305         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0739      0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20     0.457G      5.249         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 61.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0728      0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20     0.466G      5.212         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 63.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00495     0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20     0.457G      5.153         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 63.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00457     0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20     0.466G      5.088         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 61.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00686     0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      0.48G      5.026         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00571     0.0415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20     0.466G      4.951         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00724     0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20     0.457G      4.852         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00724     0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20     0.466G      4.732         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00686     0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20     0.457G      4.612         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00648     0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20     0.466G      4.482         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00648     0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20     0.457G      4.311         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00686     0.0385\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20     0.466G      4.081         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00495     0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20     0.457G      3.846         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.40it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00419     0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20     0.463G      3.584         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.40it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00343      0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.226 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_v52\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_v52\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSprop_noAug_v52\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0731      0.205\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_v52\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_v52\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001528F22CF10>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.13923809677362442\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.07314285635948181, 'metrics/accuracy_top5': 0.20533333718776703, 'fitness': 0.13923809677362442}\n",
       "save_dir: WindowsPath('runs/classify/RMSprop_noAug_v52')\n",
       "speed: {'preprocess': 0.0784467061360677, 'inference': 0.07698431469145275, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.07314285635948181\n",
       "top5: 0.20533333718776703"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and no augmentations(starting learning rate = 0.01, final learning rate = 0.001)\n",
    "mymodel_RMSprop_noAug_v4 = YOLO(\"yolov8n-cls.pt\").to(device)\n",
    "mymodel_RMSprop_noAug_v4.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    lr0=0.01,\n",
    "    lrf=0.001,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSprop_noAug_v4'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mymodel_RMSprop_noAug_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.70  Python-3.8.18 torch-2.2.2 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 77.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.032      0.103\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train43342\u001b[0m\n",
      "Top1 accuracy is 0.0320 and Top5 accuracy is 0.1032\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RMSprop_noAug_v4.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=NAdam_noAug2, exist_ok=False, pretrained=True, optimizer=NAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\NAdam_noAug2\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m NAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\NAdam_noAug2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.466G       2.03         27        224: 100%|██████████| 2645/2645 [01:25<00:00, 30.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 42.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.671      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.514G      1.418         27        224: 100%|██████████| 2645/2645 [01:16<00:00, 34.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.81      0.943\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.491G      1.191         27        224: 100%|██████████| 2645/2645 [01:08<00:00, 38.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 48.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.843      0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.516G      1.113         27        224: 100%|██████████| 2645/2645 [01:08<00:00, 38.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 48.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.881       0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.491G     0.9881         27        224: 100%|██████████| 2645/2645 [01:08<00:00, 38.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.897      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.516G      0.869         27        224: 100%|██████████| 2645/2645 [01:08<00:00, 38.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.918      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.491G     0.7413         27        224: 100%|██████████| 2645/2645 [01:08<00:00, 38.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.516G     0.6161         27        224: 100%|██████████| 2645/2645 [01:08<00:00, 38.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.934       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.491G     0.4608         27        224: 100%|██████████| 2645/2645 [01:08<00:00, 38.66it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.943      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.516G     0.3045         27        224: 100%|██████████| 2645/2645 [01:08<00:00, 38.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.947      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.210 hours.\n",
      "Optimizer stripped from runs\\classify\\NAdam_noAug2\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\NAdam_noAug2\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\NAdam_noAug2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.947      0.993\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_noAug2\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_noAug2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C7C880C700>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.969904750585556\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9470475912094116, 'metrics/accuracy_top5': 0.9927619099617004, 'fitness': 0.969904750585556}\n",
       "save_dir: WindowsPath('runs/classify/NAdam_noAug2')\n",
       "speed: {'preprocess': 0.06285158793131511, 'inference': 0.13904735020228795, 'loss': 0.0011427743094308035, 'postprocess': 0.0011427743094308035}\n",
       "task: 'classify'\n",
       "top1: 0.9470475912094116\n",
       "top5: 0.9927619099617004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with NAdam optimizer and no augmentations\n",
    "mymodel_NAdam_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_NAdam_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='NAdam',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='NAdam_noAug',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 63.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.947      0.993\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_noAug22\u001b[0m\n",
      "Top1 accuracy is 0.9470 and Top5 accuracy is 0.9928\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_NAdam_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RAdam_noAug, exist_ok=False, pretrained=True, optimizer=RAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RAdam_noAug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RAdam_noAug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      0.51G       2.38         27        224: 100%|██████████| 2645/2645 [01:23<00:00, 31.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.636      0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      0.56G      1.599         27        224: 100%|██████████| 2645/2645 [01:15<00:00, 35.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.789      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.537G      1.342         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 38.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      0.56G      1.236         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.865      0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.537G      1.089         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.89      0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.562G     0.9425         27        224: 100%|██████████| 2645/2645 [01:03<00:00, 41.95it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.912      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.537G     0.7982         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      0.56G     0.6538         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.934      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.537G     0.4891         27        224: 100%|██████████| 2645/2645 [01:07<00:00, 39.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.944      0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.562G     0.3233         27        224: 100%|██████████| 2645/2645 [01:02<00:00, 42.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 46.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.943      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.204 hours.\n",
      "Optimizer stripped from runs\\classify\\RAdam_noAug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RAdam_noAug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RAdam_noAug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.943      0.989\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_noAug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_noAug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C812EB4910>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9659047722816467\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9428571462631226, 'metrics/accuracy_top5': 0.9889523983001709, 'fitness': 0.9659047722816467}\n",
       "save_dir: WindowsPath('runs/classify/RAdam_noAug')\n",
       "speed: {'preprocess': 0.06705147879464285, 'inference': 0.14857174101329987, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9428571462631226\n",
       "top5: 0.9889523983001709"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RAdam optimizer and no augmentations\n",
    "mymodel_RAdam_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_RAdam_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='RAdam',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RAdam_noAug',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 57.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.943      0.989\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_noAug2\u001b[0m\n",
      "Top1 accuracy is 0.9429 and Top5 accuracy is 0.9890\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RAdam_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set of models with the following parameters:\n",
    "1. Automatic mixed precision\n",
    "2. Batch size of 32\n",
    "4. Default augmentations (see specifics below)\n",
    "5. 10 epochs\n",
    "\n",
    "## The default augmentations are:\n",
    "1. hsv_h=0.015- Controls the variation in hue.\n",
    "2. hsv_s=0.7- Controls the variation in saturation. A higher value (0.7) allows for a broader range of saturation changes.\n",
    "3. hsv_v=0.4- Controls the variation in value (brightness). A value of 0.4 allows moderate changes in brightness.\n",
    "4. translate=0.1- The range for random translation as a fraction of the image size. A value of 0.1 allows for slight shifts.\n",
    "5. scale=0.5- The range for random scaling. A value of 0.5 indicates a possibility of significant scaling.\n",
    "6. fliplr=0.5- Probability of flipping the image left to right.\n",
    "7. erasing=0.4- Probability of random erasing parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=SGD_Aug, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\SGD_Aug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\SGD_Aug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.537G      5.153         27        224: 100%|██████████| 2645/2645 [01:46<00:00, 24.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.562      0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.577G      1.779         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.843      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.577G     0.9877         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.91it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.895      0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.596G     0.7607         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.01it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.577G     0.5773         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.942      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.596G     0.4703         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.952      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.577G     0.3918         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.956      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.596G     0.3342         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.959      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.577G     0.2806         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.958      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.596G      0.243         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.96      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.298 hours.\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\SGD_Aug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.96      0.995\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C8352F0A60>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9773333370685577\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9599999785423279, 'metrics/accuracy_top5': 0.9946666955947876, 'fitness': 0.9773333370685577}\n",
       "save_dir: WindowsPath('runs/classify/SGD_Aug')\n",
       "speed: {'preprocess': 0.0796180906749907, 'inference': 0.12457266308012462, 'loss': 0.0003811064220610119, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9599999785423279\n",
       "top5: 0.9946666955947876"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with SGD optimizer and default augmentations\n",
    "mymodel_SGD_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_SGD_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='SGD',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='SGD_Aug',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 65.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.96      0.995\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug2\u001b[0m\n",
      "Top1 accuracy is 0.9600 and Top5 accuracy is 0.9947\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_SGD_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=Adam_Aug, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\Adam_Aug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\Adam_Aug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.581G      2.931         27        224: 100%|██████████| 2645/2645 [01:46<00:00, 24.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.491      0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.633G      2.314         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.743      0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.623G      2.017         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.43it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.776      0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.625G      1.892         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 34.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.828      0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      0.61G      1.712         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.855       0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.619G       1.54         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 33.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.878      0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.623G      1.353         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 34.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.894      0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.625G      1.175         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 34.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.911      0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      0.61G     0.9621         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.87it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.922      0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.619G     0.7525         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.922      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.302 hours.\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\Adam_Aug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 42.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.922      0.981\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C7C897F1C0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.951619029045105\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9219047427177429, 'metrics/accuracy_top5': 0.981333315372467, 'fitness': 0.951619029045105}\n",
       "save_dir: WindowsPath('runs/classify/Adam_Aug')\n",
       "speed: {'preprocess': 0.08990233285086496, 'inference': 0.13409732636951266, 'loss': 0.0003809247698102678, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9219047427177429\n",
       "top5: 0.981333315372467"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with Adam optimizer and default augmentations\n",
    "mymodel_Adam_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_Adam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='Adam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='Adam_Aug',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 32.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.922      0.981\n",
      "Speed: 0.1ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug2\u001b[0m\n",
      "Top1 accuracy is 0.9223 and Top5 accuracy is 0.9813\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_Adam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=AdamW_Aug, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\AdamW_Aug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\AdamW_Aug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.415G      2.682         27        224: 100%|██████████| 2645/2645 [01:48<00:00, 24.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.653      0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.463G      1.528         27        224: 100%|██████████| 2645/2645 [01:45<00:00, 25.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.831      0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.461G      1.123         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.887      0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      0.48G     0.8669         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.911      0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.463G     0.6744         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.482G     0.5386         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.946      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.463G     0.4187         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 34.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.953       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      0.48G     0.3304         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.959      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.463G     0.2423         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.961      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      0.48G     0.1784         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.957      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.302 hours.\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\AdamW_Aug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.961      0.991\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000018E87D48A30>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9761904776096344\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9611428380012512, 'metrics/accuracy_top5': 0.9912381172180176, 'fitness': 0.9761904776096344}\n",
       "save_dir: WindowsPath('runs/classify/AdamW_Aug')\n",
       "speed: {'preprocess': 0.0807566869826544, 'inference': 0.12305314200265066, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9611428380012512\n",
       "top5: 0.9912381172180176"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with AdamW optimizer and default augmentations\n",
    "mymodel_AdamW_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_AdamW_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='AdamW',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='AdamW_Aug',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 70.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.961      0.992\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug2\u001b[0m\n",
      "Top1 accuracy is 0.9611 and Top5 accuracy is 0.9916\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_AdamW_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_AdamW_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSProp_Aug, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSProp_Aug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSProp_Aug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.415G      6.258         27        224: 100%|██████████| 2645/2645 [01:45<00:00, 25.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.459G      6.037         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00229      0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.459G      5.888         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00381     0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.459G      5.951         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00229      0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.457G       5.93         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.461G      6.029         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00114    0.00838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.459G      5.966         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00152    0.00724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.459G      5.903         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.43it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00229      0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.459G      5.811         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00457     0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.459G      5.732         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00305     0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.301 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSProp_Aug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 42.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00381     0.0198\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000018E5DB8DCA0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.011809523683041334\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.003809523768723011, 'metrics/accuracy_top5': 0.019809523597359657, 'fitness': 0.011809523683041334}\n",
       "save_dir: WindowsPath('runs/classify/RMSProp_Aug')\n",
       "speed: {'preprocess': 0.09752473377046131, 'inference': 0.14361853826613652, 'loss': 0.0007621220179966518, 'postprocess': 0.0007619403657459077}\n",
       "task: 'classify'\n",
       "top1: 0.003809523768723011\n",
       "top5: 0.019809523597359657"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and default augmentations\n",
    "mymodel_RMSprop_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_RMSprop_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSProp_Aug',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 67.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00419     0.0202\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug2\u001b[0m\n",
      "Top1 accuracy is 0.0042 and Top5 accuracy is 0.0202\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RMSprop_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RMSprop_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=NAdam_Aug, exist_ok=False, pretrained=True, optimizer=NAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\NAdam_Aug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m NAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\NAdam_Aug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.424G      2.674         27        224: 100%|██████████| 2645/2645 [01:45<00:00, 25.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.606      0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.459G      2.069         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.71it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.765      0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.457G       1.81         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.796      0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.459G      1.721         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.835       0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.459G       1.57         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.88it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.861      0.952\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.461G      1.428         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.883      0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.459G      1.264         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.895       0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.459G      1.108         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.87it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 42.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.91      0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.459G     0.9131         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.921      0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.459G     0.7112         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.03it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.296 hours.\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\NAdam_Aug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.982\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000018E5DC9CB20>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9548571407794952\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9276190400123596, 'metrics/accuracy_top5': 0.9820952415466309, 'fitness': 0.9548571407794952}\n",
       "save_dir: WindowsPath('runs/classify/NAdam_Aug')\n",
       "speed: {'preprocess': 0.09447424752371653, 'inference': 0.15047645568847656, 'loss': 0.00038047063918340775, 'postprocess': 0.0011428651355561755}\n",
       "task: 'classify'\n",
       "top1: 0.9276190400123596\n",
       "top5: 0.9820952415466309"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with NAdam optimizer and default augmentations\n",
    "mymodel_NAdam_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_NAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='NAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='NAdam_Aug',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 63.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.982\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug2\u001b[0m\n",
      "Top1 accuracy is 0.9280 and Top5 accuracy is 0.9825\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mymodel_AdamW_Aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m metrics\u001b[38;5;241m.\u001b[39mtop5  \u001b[38;5;66;03m# top5 accuracy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop1 accuracy is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;241m.\u001b[39mtop1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and Top5 accuracy is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;241m.\u001b[39mtop5\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m mymodel_AdamW_Aug\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mymodel_AdamW_Aug' is not defined"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_NAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_NAdam_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RAdam_Aug, exist_ok=False, pretrained=True, optimizer=RAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RAdam_Aug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RAdam_Aug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.466G       2.97         27        224: 100%|██████████| 2645/2645 [01:46<00:00, 24.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.491      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      0.52G      2.292         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 32.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.731      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.497G      2.018         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.77      0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.505G      1.891         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.495G       1.71         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.854      0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.503G      1.534         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.875      0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.495G      1.338         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.893      0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.503G      1.168         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.91      0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.495G     0.9526         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.921      0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.505G     0.7377         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.295 hours.\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RAdam_Aug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.981\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000018E893DD340>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9521904587745667\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9230476021766663, 'metrics/accuracy_top5': 0.981333315372467, 'fitness': 0.9521904587745667}\n",
       "save_dir: WindowsPath('runs/classify/RAdam_Aug')\n",
       "speed: {'preprocess': 0.08304768516903832, 'inference': 0.12647610618954613, 'loss': 0.0, 'postprocess': 0.0019047146751767113}\n",
       "task: 'classify'\n",
       "top1: 0.9230476021766663\n",
       "top5: 0.981333315372467"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RAdam optimizer and default augmentations\n",
    "mymodel_RAdam_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_RAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='RAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RAdam_Aug',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 61.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.981\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug3\u001b[0m\n",
      "Top1 accuracy is 0.9234 and Top5 accuracy is 0.9813\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RAdam_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set of models with the following parameters:\n",
    "1. Automatic mixed precision\n",
    "2. Batch size of 32\n",
    "4. Manual augmentations (see specifics below)\n",
    "5. 10 epochs\n",
    "\n",
    "\n",
    "## The default augmentations are:\n",
    "1. hsv_h=0.015- Controls the variation in hue.\n",
    "2. hsv_s=0.7- Controls the variation in saturation. A higher value (0.7) allows for a broader range of saturation changes.\n",
    "3. hsv_v=0.4- Controls the variation in value (brightness). A value of 0.4 allows moderate changes in brightness.\n",
    "4. translate=0.1- The range for random translation as a fraction of the image size. A value of 0.1 allows for slight shifts.\n",
    "5. scale=0.5- The range for random scaling. A value of 0.5 indicates a possibility of significant scaling.\n",
    "6. fliplr=0.5- Probability of flipping the image left to right.\n",
    "7. erasing=0.0- Probability of random erasing parts of the image.\n",
    "8. degrees=45- The range for random rotation.\n",
    "9. perspective=0.3- he range for random perspective transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.76 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=SGD_Aug_no_erasing, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\SGD_Aug_no_erasing\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\SGD_Aug_no_erasing\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.417G      5.115         27        224: 100%|██████████| 2645/2645 [01:47<00:00, 24.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.559      0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.466G      1.673         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 33.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.846      0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.466G     0.8854         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.895      0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.482G     0.6561         27        224: 100%|██████████| 2645/2645 [01:36<00:00, 27.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.466G     0.4841         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.946      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.474G     0.3832         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.954      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.466G     0.3126         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.958      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.482G     0.2546         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.95it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.959      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.466G     0.2095         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.962      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.474G     0.1765         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.961      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.297 hours.\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug_no_erasing\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug_no_erasing\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\SGD_Aug_no_erasing\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.962      0.996\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_no_erasing\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_no_erasing\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001CA8D04B490>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9788571298122406\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.961904764175415, 'metrics/accuracy_top5': 0.9958094954490662, 'fitness': 0.9788571298122406}\n",
       "save_dir: WindowsPath('runs/classify/SGD_Aug_no_erasing')\n",
       "speed: {'preprocess': 0.10515467325846353, 'inference': 0.16493760971795945, 'loss': 0.0003807431175595238, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.961904764175415\n",
       "top5: 0.9958094954490662"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with SGD optimizer and manual augmentations\n",
    "mymodel_SGD_Aug = YOLO(\"yolov8n-cls.pt\").to(device)\n",
    "mymodel_SGD_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='SGD',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='SGD_Aug_no_erasing',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 68.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.962      0.996\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_no_erasing2\u001b[0m\n",
      "Top1 accuracy is 0.9619 and Top5 accuracy is 0.9958\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_SGD_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_SGD_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.76 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=Adam_Aug_no_erasing, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\Adam_Aug_no_erasing\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\Adam_Aug_no_erasing\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.432G      2.771         27        224: 100%|██████████| 2645/2645 [01:27<00:00, 30.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.547      0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.472G      2.124         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.91it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.715      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.472G       1.84         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.783      0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.497G      1.713         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.834      0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.472G      1.527         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.865       0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.497G      1.367         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.886      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.472G      1.193         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.897      0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.497G      1.019         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.912       0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.474G     0.8261         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.919      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.497G     0.6283         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.290 hours.\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug_no_erasing\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug_no_erasing\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\Adam_Aug_no_erasing\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 42.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.924      0.983\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_no_erasing\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_no_erasing\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001CA8CCD0C70>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9535238146781921\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9238095283508301, 'metrics/accuracy_top5': 0.9832381010055542, 'fitness': 0.9535238146781921}\n",
       "save_dir: WindowsPath('runs/classify/Adam_Aug_no_erasing')\n",
       "speed: {'preprocess': 0.09789376031784784, 'inference': 0.15944807870047434, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9238095283508301\n",
       "top5: 0.9832381010055542"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with Adam optimizer and manual augmentations\n",
    "mymodel_Adam_Aug = YOLO(\"yolov8n-cls.pt\").to(device)\n",
    "mymodel_Adam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='Adam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='Adam_Aug_no_erasing',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 62.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.924      0.983\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_no_erasing2\u001b[0m\n",
      "Top1 accuracy is 0.9238 and Top5 accuracy is 0.9832\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_Adam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_Adam_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.76 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=AdamW_Aug_no_erasing, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\AdamW_Aug_no_erasing\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\AdamW_Aug_no_erasing\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.415G       2.53         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.7      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.463G      1.369         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.837      0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.461G     0.9822         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.885      0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      0.48G     0.7432         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.916       0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.463G      0.561         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.926      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.482G     0.4335         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.947      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.463G     0.3262         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.952      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      0.48G     0.2387         27        224: 100%|██████████| 2645/2645 [01:40<00:00, 26.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.952      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.463G      0.165         27        224: 100%|██████████| 2645/2645 [01:40<00:00, 26.19it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.952      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      0.48G     0.1109         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.955      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.293 hours.\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug_no_erasing\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug_no_erasing\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\AdamW_Aug_no_erasing\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.955      0.992\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_no_erasing\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_no_erasing\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000018B0541FAC0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.973333328962326\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9546666741371155, 'metrics/accuracy_top5': 0.9919999837875366, 'fitness': 0.973333328962326}\n",
       "save_dir: WindowsPath('runs/classify/AdamW_Aug_no_erasing')\n",
       "speed: {'preprocess': 0.08190536499023438, 'inference': 0.11942481994628906, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9546666741371155\n",
       "top5: 0.9919999837875366"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with AdamW optimizer and manual augmentations\n",
    "mymodel_AdamW_Aug = YOLO(\"yolov8n-cls.pt\").to(device)\n",
    "mymodel_AdamW_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='AdamW',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='AdamW_Aug_no_erasing',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 65.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.955      0.992\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_no_erasing2\u001b[0m\n",
      "Top1 accuracy is 0.9547 and Top5 accuracy is 0.9920\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_AdamW_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_AdamW_Aug\n",
    "del metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.76 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSProp_Aug_no_erasing, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSProp_Aug_no_erasing\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSProp_Aug_no_erasing\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.417G      6.093         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00152     0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.463G      5.826         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.91it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00457      0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.463G      5.675         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00152     0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.474G      5.715         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00381     0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.463G       5.63         27        224: 100%|██████████| 2645/2645 [01:40<00:00, 26.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00229      0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.474G       5.54         27        224: 100%|██████████| 2645/2645 [01:40<00:00, 26.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00495     0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.463G      5.433         27        224: 100%|██████████| 2645/2645 [01:40<00:00, 26.22it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00457     0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.474G      5.289         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00571     0.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.463G      5.117         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.008     0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.474G      4.883         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0099     0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.293 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug_no_erasing\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug_no_erasing\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSProp_Aug_no_erasing\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00914     0.0442\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug_no_erasing\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug_no_erasing\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000018B099A7340>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.02666666731238365\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.009142857044935226, 'metrics/accuracy_top5': 0.04419047757983208, 'fitness': 0.02666666731238365}\n",
       "save_dir: WindowsPath('runs/classify/RMSProp_Aug_no_erasing')\n",
       "speed: {'preprocess': 0.08267102922712054, 'inference': 0.15161087399437315, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.009142857044935226\n",
       "top5: 0.04419047757983208"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and manual augmentations\n",
    "mymodel_RMSprop_Aug = YOLO(\"yolov8n-cls.pt\").to(device)\n",
    "mymodel_RMSprop_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSProp_Aug_no_erasing',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 61.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0099     0.0457\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug_no_erasing2\u001b[0m\n",
      "Top1 accuracy is 0.0099 and Top5 accuracy is 0.0457\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RMSprop_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RMSprop_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.76 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=NAdam_Aug_no_erasing, exist_ok=False, pretrained=True, optimizer=NAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\NAdam_Aug_no_erasing\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m NAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\NAdam_Aug_no_erasing\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.417G      2.545         27        224: 100%|██████████| 2645/2645 [01:38<00:00, 26.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.58      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.459G      1.895         27        224: 100%|██████████| 2645/2645 [01:37<00:00, 27.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.768      0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.459G      1.635         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.782      0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.466G      1.551         27        224: 100%|██████████| 2645/2645 [01:31<00:00, 29.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.834      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.459G      1.404         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.874      0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.466G      1.265         27        224: 100%|██████████| 2645/2645 [01:37<00:00, 27.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.887      0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.459G      1.125         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 33.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.905      0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.466G     0.9666         27        224: 100%|██████████| 2645/2645 [01:40<00:00, 26.22it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 52.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.918      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.459G     0.7887         27        224: 100%|██████████| 2645/2645 [01:33<00:00, 28.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.925      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.466G      0.595         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.932      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.286 hours.\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug_no_erasing\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug_no_erasing\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\NAdam_Aug_no_erasing\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.932      0.986\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_no_erasing\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_no_erasing\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000018B06A35D90>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9590476155281067\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9318095445632935, 'metrics/accuracy_top5': 0.9862856864929199, 'fitness': 0.9590476155281067}\n",
       "save_dir: WindowsPath('runs/classify/NAdam_Aug_no_erasing')\n",
       "speed: {'preprocess': 0.10552651541573661, 'inference': 0.1535199483235677, 'loss': 0.0007619403657459077, 'postprocess': 0.0003810155959356399}\n",
       "task: 'classify'\n",
       "top1: 0.9318095445632935\n",
       "top5: 0.9862856864929199"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with NAdam optimizer and manual augmentations\n",
    "mymodel_NAdam_Aug = YOLO(\"yolov8n-cls.pt\").to(device)\n",
    "mymodel_NAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='NAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='NAdam_Aug_no_erasing',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 62.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.932      0.986\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_no_erasing2\u001b[0m\n",
      "Top1 accuracy is 0.9318 and Top5 accuracy is 0.9863\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_NAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_NAdam_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.76 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RAdam_Aug_no_erasing, exist_ok=False, pretrained=True, optimizer=RAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RAdam_Aug_no_erasing\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RAdam_Aug_no_erasing\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.426G       2.84         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.51it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.544      0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.457G      2.113         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.731        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.459G      1.823         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.77      0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.482G      1.714         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.831      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.459G      1.542         27        224: 100%|██████████| 2645/2645 [01:36<00:00, 27.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.862      0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.482G      1.367         27        224: 100%|██████████| 2645/2645 [01:37<00:00, 27.26it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.89       0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.459G      1.194         27        224: 100%|██████████| 2645/2645 [01:40<00:00, 26.26it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.904      0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.482G      1.016         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 26.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.918      0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.459G     0.8254         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.82it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.926      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.482G     0.6261         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.92it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.293 hours.\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug_no_erasing\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug_no_erasing\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RAdam_Aug_no_erasing\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.985\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_no_erasing\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_no_erasing\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000018AF1054940>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9565714299678802\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9283809661865234, 'metrics/accuracy_top5': 0.9847618937492371, 'fitness': 0.9565714299678802}\n",
       "save_dir: WindowsPath('runs/classify/RAdam_Aug_no_erasing')\n",
       "speed: {'preprocess': 0.09218797229585193, 'inference': 0.14648155939011348, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9283809661865234\n",
       "top5: 0.9847618937492371"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RAdam optimizer and manual augmentations\n",
    "mymodel_RAdam_Aug = YOLO(\"yolov8n-cls.pt\").to(device)\n",
    "mymodel_RAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='RAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RAdam_Aug_no_erasing',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 69.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.985\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_no_erasing2\u001b[0m\n",
      "Top1 accuracy is 0.9280 and Top5 accuracy is 0.9848\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RAdam_Aug"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPGINKQxVpQQf9gWtJTSZp1",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
