{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for YOLOv8l-cls models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5655,
     "status": "ok",
     "timestamp": 1722438208361,
     "user": {
      "displayName": "דור דנינו",
      "userId": "17259148283236873173"
     },
     "user_tz": -180
    },
    "id": "dD916Btcr3Sl",
    "outputId": "171236cb-5be3-4f57-bf99-23c52c9aad36"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set of models with the following parameters:\n",
    "1. Automatic mixed precision\n",
    "2. Batch size of 32\n",
    "4. No augmentations\n",
    "5. 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErBvqpBYr9Yf",
    "outputId": "0b02831e-e56e-472b-b67a-8b9b7dfdad54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=SGD_noAug_l, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\SGD_noAug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\SGD_noAug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      2.46G      5.017         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.61it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.744      0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10       2.6G     0.9326         27        224: 100%|██████████| 2645/2645 [02:34<00:00, 17.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.941      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      2.63G     0.3139         27        224: 100%|██████████| 2645/2645 [02:28<00:00, 17.87it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.963      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      2.72G     0.1523         27        224: 100%|██████████| 2645/2645 [02:27<00:00, 17.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.973      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      2.62G    0.05674         27        224: 100%|██████████| 2645/2645 [02:26<00:00, 18.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.979      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      2.65G    0.02483         27        224: 100%|██████████| 2645/2645 [02:27<00:00, 17.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.98      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      2.62G     0.0146         27        224: 100%|██████████| 2645/2645 [02:27<00:00, 17.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.982      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      2.65G    0.01133         27        224: 100%|██████████| 2645/2645 [02:26<00:00, 18.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.982      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10       2.6G   0.009484         27        224: 100%|██████████| 2645/2645 [02:26<00:00, 18.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.982      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      2.64G   0.008899         27        224: 100%|██████████| 2645/2645 [02:26<00:00, 18.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.982      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.427 hours.\n",
      "Optimizer stripped from runs\\classify\\SGD_noAug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\SGD_noAug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\SGD_noAug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.982      0.998\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_noAug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_noAug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000023CA5C30880>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9902856945991516\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9824761748313904, 'metrics/accuracy_top5': 0.9980952143669128, 'fitness': 0.9902856945991516}\n",
       "save_dir: WindowsPath('runs/classify/SGD_noAug_l')\n",
       "speed: {'preprocess': 0.04380898248581659, 'inference': 0.4868521009172712, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9824761748313904\n",
       "top5: 0.9980952143669128"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with SGD optimizer and no augmentations\n",
    "mymodel_SGD_noAug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_SGD_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='SGD',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='SGD_noAug_l',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "error",
     "timestamp": 1722429687601,
     "user": {
      "displayName": "דור דנינו",
      "userId": "17259148283236873173"
     },
     "user_tz": -180
    },
    "id": "q_BqhL_5sCXf",
    "outputId": "f91a0446-c12f-417b-f699-c1b630d13030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 32.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.982      0.998\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_noAug_l2\u001b[0m\n",
      "Top1 accuracy is 0.9825 and Top5 accuracy is 0.9981\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_SGD_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=Adam_noAug_l, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\Adam_noAug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\Adam_noAug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      2.58G      2.383         27        224: 100%|██████████| 2645/2645 [02:48<00:00, 15.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.543       0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      2.79G      1.941         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.759      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      2.79G      1.525         27        224: 100%|██████████| 2645/2645 [02:30<00:00, 17.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.793      0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10       2.8G      1.365         27        224: 100%|██████████| 2645/2645 [02:32<00:00, 17.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.852      0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      2.79G      1.184         27        224: 100%|██████████| 2645/2645 [02:31<00:00, 17.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.884      0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      2.88G      1.012         27        224: 100%|██████████| 2645/2645 [02:34<00:00, 17.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.912       0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      2.79G     0.8576         27        224: 100%|██████████| 2645/2645 [02:35<00:00, 16.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      2.88G     0.7091         27        224: 100%|██████████| 2645/2645 [02:36<00:00, 16.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.938      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10       2.8G     0.5393         27        224: 100%|██████████| 2645/2645 [02:35<00:00, 16.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.941      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      2.88G     0.3707         27        224: 100%|██████████| 2645/2645 [02:36<00:00, 16.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.946      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.448 hours.\n",
      "Optimizer stripped from runs\\classify\\Adam_noAug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\Adam_noAug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\Adam_noAug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 27.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.946      0.989\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_noAug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_noAug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000023C9A02B5E0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9676190614700317\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9459047913551331, 'metrics/accuracy_top5': 0.9893333315849304, 'fitness': 0.9676190614700317}\n",
       "save_dir: WindowsPath('runs/classify/Adam_noAug_l')\n",
       "speed: {'preprocess': 0.05164210001627604, 'inference': 0.5066574641636439, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9459047913551331\n",
       "top5: 0.9893333315849304"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with Adam optimizer and no augmentations\n",
    "mymodel_Adam_noAug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_Adam_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='Adam',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='Adam_noAug_l',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 57.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.945      0.992\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_noAug2\u001b[0m\n",
      "Top1 accuracy is 0.9451 and Top5 accuracy is 0.9916\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_Adam_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.78 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=AdamW_noAug_l, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\AdamW_noAug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\AdamW_noAug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10       2.5G      1.854         27        224: 100%|██████████| 2645/2645 [03:07<00:00, 14.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.771      0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      2.64G     0.9498         27        224: 100%|██████████| 2645/2645 [02:59<00:00, 14.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.89      0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      2.63G     0.6015         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.24it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.929      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      2.65G     0.4062         27        224: 100%|██████████| 2645/2645 [02:46<00:00, 15.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.943      0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      2.63G     0.2509         27        224: 100%|██████████| 2645/2645 [02:48<00:00, 15.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.955      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      2.65G     0.1532         27        224: 100%|██████████| 2645/2645 [02:45<00:00, 16.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.964      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      2.64G    0.08654         27        224: 100%|██████████| 2645/2645 [02:45<00:00, 15.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.964      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      2.73G    0.04557         27        224: 100%|██████████| 2645/2645 [02:46<00:00, 15.92it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.971      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      2.64G    0.01878         27        224: 100%|██████████| 2645/2645 [02:45<00:00, 16.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.973      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      2.74G   0.005638         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.973      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.485 hours.\n",
      "Optimizer stripped from runs\\classify\\AdamW_noAug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\AdamW_noAug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\AdamW_noAug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.973      0.995\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_noAug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_noAug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x00000259940A82E0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9838095307350159\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9729523658752441, 'metrics/accuracy_top5': 0.9946666955947876, 'fitness': 0.9838095307350159}\n",
       "save_dir: WindowsPath('runs/classify/AdamW_noAug_l')\n",
       "speed: {'preprocess': 0.048366274152483256, 'inference': 0.49180802844819566, 'loss': 0.0003807431175595238, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9729523658752441\n",
       "top5: 0.9946666955947876"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with AdamW optimizer and no augmentations\n",
    "mymodel_AdamW_noAug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_AdamW_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='AdamW',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='AdamW_noAug_l',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 30.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.973      0.995\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_noAug_l2\u001b[0m\n",
      "Top1 accuracy is 0.9733 and Top5 accuracy is 0.9950\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_AdamW_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSprop_noAug_l, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSprop_noAug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSprop_noAug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.22G      6.001         27        224: 100%|██████████| 2645/2645 [02:54<00:00, 15.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      3.44G      5.494         27        224: 100%|██████████| 2645/2645 [02:47<00:00, 15.83it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019      0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      3.43G      5.288         27        224: 100%|██████████| 2645/2645 [02:41<00:00, 16.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00305     0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      3.44G      5.323         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 27.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00267     0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      3.41G      5.223         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019     0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      3.45G      5.111         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      3.43G      4.984         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.45G      4.799         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 27.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      3.42G      4.525         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.51it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.44G      4.196         27        224: 100%|██████████| 2645/2645 [02:41<00:00, 16.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 27.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.467 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\RMSprop_noAug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00305     0.0198\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000023C9A1AFF70>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.011428571306169033\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.003047619014978409, 'metrics/accuracy_top5': 0.019809523597359657, 'fitness': 0.011428571306169033}\n",
       "save_dir: WindowsPath('runs/classify/RMSprop_noAug_l')\n",
       "speed: {'preprocess': 0.058285031999860494, 'inference': 0.4853151412237258, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.003047619014978409\n",
       "top5: 0.019809523597359657"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and no augmentations(starting learning rate = 0.01)\n",
    "mymodel_RMSprop_noAug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_RMSprop_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSprop_noAug_l'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=NAdam_noAug_l, exist_ok=False, pretrained=True, optimizer=NAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\NAdam_noAug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m NAdam(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\NAdam_noAug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.98G      2.123         27        224: 100%|██████████| 2645/2645 [03:05<00:00, 14.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.568      0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      4.04G      1.707         27        224: 100%|██████████| 2645/2645 [02:53<00:00, 15.22it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 26.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.793       0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      4.05G      1.346         27        224: 100%|██████████| 2645/2645 [02:36<00:00, 16.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.826      0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      4.15G      1.219         27        224: 100%|██████████| 2645/2645 [02:32<00:00, 17.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.871      0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      4.06G      1.069         27        224: 100%|██████████| 2645/2645 [02:31<00:00, 17.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.896      0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      4.07G     0.9235         27        224: 100%|██████████| 2645/2645 [02:31<00:00, 17.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.915      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      4.05G     0.7991         27        224: 100%|██████████| 2645/2645 [02:31<00:00, 17.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.924      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      4.07G     0.6592         27        224: 100%|██████████| 2645/2645 [02:31<00:00, 17.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.937      0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      4.06G     0.5063         27        224: 100%|██████████| 2645/2645 [02:31<00:00, 17.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.943      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      4.07G     0.3411         27        224: 100%|██████████| 2645/2645 [02:31<00:00, 17.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.948      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.453 hours.\n",
      "Optimizer stripped from runs\\classify\\NAdam_noAug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\NAdam_noAug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\NAdam_noAug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.948      0.989\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_noAug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_noAug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000023CA5D98280>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9685714244842529\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.948190450668335, 'metrics/accuracy_top5': 0.9889523983001709, 'fitness': 0.9685714244842529}\n",
       "save_dir: WindowsPath('runs/classify/NAdam_noAug_l')\n",
       "speed: {'preprocess': 0.05600020999000186, 'inference': 0.47330756414504277, 'loss': 0.0, 'postprocess': 0.0003809247698102678}\n",
       "task: 'classify'\n",
       "top1: 0.948190450668335\n",
       "top5: 0.9889523983001709"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with NAdam optimizer and no augmentations\n",
    "mymodel_NAdam_noAug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_NAdam_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='NAdam',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='NAdam_noAug_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 31.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.948      0.989\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_noAug_l2\u001b[0m\n",
      "Top1 accuracy is 0.9478 and Top5 accuracy is 0.9886\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_NAdam_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RAdam_noAug_l, exist_ok=False, pretrained=True, optimizer=RAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RAdam_noAug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RAdam(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RAdam_noAug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      4.51G      2.406         27        224: 100%|██████████| 2645/2645 [02:53<00:00, 15.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.509       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      4.83G      1.968         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.26it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.752      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      4.83G      1.547         27        224: 100%|██████████| 2645/2645 [02:33<00:00, 17.22it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.807      0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      4.92G      1.368         27        224: 100%|██████████| 2645/2645 [02:32<00:00, 17.34it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.859      0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      4.84G      1.187         27        224: 100%|██████████| 2645/2645 [02:33<00:00, 17.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.882      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      4.85G      1.014         27        224: 100%|██████████| 2645/2645 [02:34<00:00, 17.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.91      0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      4.83G     0.8556         27        224: 100%|██████████| 2645/2645 [02:35<00:00, 17.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      4.85G      0.709         27        224: 100%|██████████| 2645/2645 [02:34<00:00, 17.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.94      0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      4.84G     0.5378         27        224: 100%|██████████| 2645/2645 [02:34<00:00, 17.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.944      0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      4.85G     0.3687         27        224: 100%|██████████| 2645/2645 [02:35<00:00, 17.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.949       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.453 hours.\n",
      "Optimizer stripped from runs\\classify\\RAdam_noAug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\RAdam_noAug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\RAdam_noAug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.949       0.99\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_noAug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_noAug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000023C9A072400>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.969904750585556\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9493333101272583, 'metrics/accuracy_top5': 0.9904761910438538, 'fitness': 0.969904750585556}\n",
       "save_dir: WindowsPath('runs/classify/RAdam_noAug_l')\n",
       "speed: {'preprocess': 0.05201921008882069, 'inference': 0.49676631745837985, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9493333101272583\n",
       "top5: 0.9904761910438538"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RAdam optimizer and no augmentations\n",
    "mymodel_RAdam_noAug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_RAdam_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='RAdam',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RAdam_noAug_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 32.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.949       0.99\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_noAug_l2\u001b[0m\n",
      "Top1 accuracy is 0.9493 and Top5 accuracy is 0.9905\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RAdam_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set of models with the following parameters:\n",
    "1. Automatic mixed precision\n",
    "2. Batch size of 32\n",
    "4. Default augmentations (see specifics below)\n",
    "5. 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The default augmentations are:\n",
    "1. hsv_h=0.015- Controls the variation in hue.\n",
    "2. hsv_s=0.7- Controls the variation in saturation. A higher value (0.7) allows for a broader range of saturation changes.\n",
    "3. hsv_v=0.4- Controls the variation in value (brightness). A value of 0.4 allows moderate changes in brightness.\n",
    "4. translate=0.1- The range for random translation as a fraction of the image size. A value of 0.1 allows for slight shifts.\n",
    "5. scale=0.5- The range for random scaling. A value of 0.5 indicates a possibility of significant scaling.\n",
    "6. fliplr=0.5- Probability of flipping the image left to right.\n",
    "7. erasing=0.4- Probability of random erasing parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=SGD_Aug_l, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\SGD_Aug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\SGD_Aug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10       5.3G      5.306         27        224: 100%|██████████| 2645/2645 [02:41<00:00, 16.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.628      0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      5.44G      1.423         27        224: 100%|██████████| 2645/2645 [02:33<00:00, 17.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.91      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      5.45G     0.5875         27        224: 100%|██████████| 2645/2645 [02:27<00:00, 17.92it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.945      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      5.47G     0.4044         27        224: 100%|██████████| 2645/2645 [02:27<00:00, 17.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.965      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      5.45G     0.2846         27        224: 100%|██████████| 2645/2645 [02:27<00:00, 17.92it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.974      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      5.47G     0.2169         27        224: 100%|██████████| 2645/2645 [02:27<00:00, 17.96it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.979      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      5.44G     0.1695         27        224: 100%|██████████| 2645/2645 [02:26<00:00, 18.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.976      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      5.48G       0.14         27        224: 100%|██████████| 2645/2645 [02:27<00:00, 17.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.98      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      5.44G     0.1115         27        224: 100%|██████████| 2645/2645 [02:26<00:00, 18.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.981      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      5.54G    0.09424         27        224: 100%|██████████| 2645/2645 [02:26<00:00, 18.08it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.981      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.429 hours.\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\SGD_Aug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.981      0.998\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000023CB61AF070>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9895238280296326\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.980571448802948, 'metrics/accuracy_top5': 0.9984762072563171, 'fitness': 0.9895238280296326}\n",
       "save_dir: WindowsPath('runs/classify/SGD_Aug_l')\n",
       "speed: {'preprocess': 0.051854451497395836, 'inference': 0.48513167245047434, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.980571448802948\n",
       "top5: 0.9984762072563171"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with SGD optimizer and default augmentations\n",
    "mymodel_SGD_Aug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_SGD_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='SGD',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='SGD_Aug_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 30.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.981      0.998\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_l2\u001b[0m\n",
      "Top1 accuracy is 0.9810 and Top5 accuracy is 0.9985\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_SGD_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=Adam_Aug_l, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\Adam_Aug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\Adam_Aug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10       2.5G      3.242         27        224: 100%|██████████| 2645/2645 [02:48<00:00, 15.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.199      0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      2.64G      2.844         27        224: 100%|██████████| 2645/2645 [02:43<00:00, 16.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.688      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      2.63G      2.307         27        224: 100%|██████████| 2645/2645 [02:31<00:00, 17.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.75      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      2.65G      2.093         27        224: 100%|██████████| 2645/2645 [02:31<00:00, 17.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.8      0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      2.63G      1.864         27        224: 100%|██████████| 2645/2645 [02:30<00:00, 17.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.85      0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      2.65G       1.66         27        224: 100%|██████████| 2645/2645 [02:30<00:00, 17.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.868      0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      2.64G      1.444         27        224: 100%|██████████| 2645/2645 [02:36<00:00, 16.88it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.891      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      2.73G      1.263         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906      0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      2.64G      1.035         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.916      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      2.74G     0.8157         27        224: 100%|██████████| 2645/2645 [02:41<00:00, 16.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.92      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.452 hours.\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\Adam_Aug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.92      0.982\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E194406B20>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9512380957603455\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9200000166893005, 'metrics/accuracy_top5': 0.9824761748313904, 'fitness': 0.9512380957603455}\n",
       "save_dir: WindowsPath('runs/classify/Adam_Aug_l')\n",
       "speed: {'preprocess': 0.04934065682547433, 'inference': 0.5057093302408855, 'loss': 0.0, 'postprocess': 0.000381378900437128}\n",
       "task: 'classify'\n",
       "top1: 0.9200000166893005\n",
       "top5: 0.9824761748313904"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with Adam optimizer and default augmentations\n",
    "mymodel_Adam_Aug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_Adam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='Adam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='Adam_Aug_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 30.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.92      0.982\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_l2\u001b[0m\n",
      "Top1 accuracy is 0.9204 and Top5 accuracy is 0.9825\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_Adam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=AdamW_Aug_l, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\AdamW_Aug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\AdamW_Aug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10       3.1G      2.538         27        224: 100%|██████████| 2645/2645 [03:10<00:00, 13.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.686      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      3.44G      1.469         27        224: 100%|██████████| 2645/2645 [02:54<00:00, 15.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.862      0.959\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      3.41G      1.029         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.901      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      3.51G     0.7696         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.937      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      3.42G     0.5775         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.949      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      3.43G     0.4499         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.963      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      3.42G     0.3412         27        224: 100%|██████████| 2645/2645 [02:43<00:00, 16.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.965      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.44G     0.2568         27        224: 100%|██████████| 2645/2645 [02:44<00:00, 16.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.967      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      3.41G     0.1789         27        224: 100%|██████████| 2645/2645 [02:43<00:00, 16.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.44G     0.1233         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.26it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.480 hours.\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\AdamW_Aug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 27.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.996\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E19C694AF0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9824762046337128\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9687619209289551, 'metrics/accuracy_top5': 0.9961904883384705, 'fitness': 0.9824762046337128}\n",
       "save_dir: WindowsPath('runs/classify/AdamW_Aug_l')\n",
       "speed: {'preprocess': 0.04645365760439918, 'inference': 0.507643290928432, 'loss': 0.0, 'postprocess': 0.0003809247698102678}\n",
       "task: 'classify'\n",
       "top1: 0.9687619209289551\n",
       "top5: 0.9961904883384705"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with AdamW optimizer and default augmentations\n",
    "mymodel_AdamW_Aug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_AdamW_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='AdamW',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='AdamW_Aug_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.996\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_l2\u001b[0m\n",
      "Top1 accuracy is 0.9691 and Top5 accuracy is 0.9962\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_AdamW_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_AdamW_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSProp_Aug, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSProp_Aug\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSProp_Aug\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.415G      6.258         27        224: 100%|██████████| 2645/2645 [01:45<00:00, 25.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.459G      6.037         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00229      0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.459G      5.888         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00381     0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.459G      5.951         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00229      0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.457G       5.93         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.461G      6.029         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00114    0.00838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.459G      5.966         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00152    0.00724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.459G      5.903         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.43it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00229      0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.459G      5.811         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00457     0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.459G      5.732         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00305     0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.301 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSProp_Aug\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 42.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00381     0.0198\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000018E5DB8DCA0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.011809523683041334\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.003809523768723011, 'metrics/accuracy_top5': 0.019809523597359657, 'fitness': 0.011809523683041334}\n",
       "save_dir: WindowsPath('runs/classify/RMSProp_Aug')\n",
       "speed: {'preprocess': 0.09752473377046131, 'inference': 0.14361853826613652, 'loss': 0.0007621220179966518, 'postprocess': 0.0007619403657459077}\n",
       "task: 'classify'\n",
       "top1: 0.003809523768723011\n",
       "top5: 0.019809523597359657"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and default augmentations\n",
    "mymodel_RMSprop_Aug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_RMSprop_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSProp_Aug_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 67.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00419     0.0202\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug2\u001b[0m\n",
      "Top1 accuracy is 0.0042 and Top5 accuracy is 0.0202\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RMSprop_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RMSprop_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=NAdam_Aug_l, exist_ok=False, pretrained=True, optimizer=NAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\NAdam_Aug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m NAdam(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\NAdam_Aug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.22G      2.873         27        224: 100%|██████████| 2645/2645 [03:16<00:00, 13.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.521      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      3.42G      2.492         27        224: 100%|██████████| 2645/2645 [03:04<00:00, 14.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.741      0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      3.41G      2.034         27        224: 100%|██████████| 2645/2645 [02:47<00:00, 15.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.786      0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      3.53G      1.882         27        224: 100%|██████████| 2645/2645 [02:45<00:00, 15.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.824      0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      3.41G      1.693         27        224: 100%|██████████| 2645/2645 [02:46<00:00, 15.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.868       0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      3.52G      1.529         27        224: 100%|██████████| 2645/2645 [02:46<00:00, 15.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.878      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      3.42G      1.342         27        224: 100%|██████████| 2645/2645 [02:48<00:00, 15.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.902      0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.53G      1.178         27        224: 100%|██████████| 2645/2645 [02:46<00:00, 15.87it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.921      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      3.42G     0.9662         27        224: 100%|██████████| 2645/2645 [02:47<00:00, 15.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.927      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.44G     0.7599         27        224: 100%|██████████| 2645/2645 [02:46<00:00, 15.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.493 hours.\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\NAdam_Aug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 25.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.984\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E19C7DD040>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9569523930549622\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9295238256454468, 'metrics/accuracy_top5': 0.9843809604644775, 'fitness': 0.9569523930549622}\n",
       "save_dir: WindowsPath('runs/classify/NAdam_Aug_l')\n",
       "speed: {'preprocess': 0.0504744393484933, 'inference': 0.5329291025797527, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9295238256454468\n",
       "top5: 0.9843809604644775"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with NAdam optimizer and default augmentations\n",
    "mymodel_NAdam_Aug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_NAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='NAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='NAdam_Aug_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 30.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.929      0.984\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_l2\u001b[0m\n",
      "Top1 accuracy is 0.9291 and Top5 accuracy is 0.9844\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_NAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_NAdam_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RAdam_Aug_l, exist_ok=False, pretrained=True, optimizer=RAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RAdam_Aug_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RAdam(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RAdam_Aug_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.21G      3.107         27        224: 100%|██████████| 2645/2645 [03:11<00:00, 13.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.395      0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      3.42G      2.869         27        224: 100%|██████████| 2645/2645 [02:58<00:00, 14.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.657      0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      3.41G      2.345         27        224: 100%|██████████| 2645/2645 [02:45<00:00, 16.03it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.75      0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      3.43G      2.127         27        224: 100%|██████████| 2645/2645 [02:44<00:00, 16.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.805      0.935\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      3.41G      1.867         27        224: 100%|██████████| 2645/2645 [02:44<00:00, 16.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.844      0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      3.43G      1.671         27        224: 100%|██████████| 2645/2645 [02:44<00:00, 16.04it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.874      0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10       3.4G      1.435         27        224: 100%|██████████| 2645/2645 [02:43<00:00, 16.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.894       0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.43G      1.256         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.907      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      3.41G      1.024         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.922      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.43G      0.798         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.925      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.482 hours.\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\RAdam_Aug_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 26.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.925      0.984\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E19947FD60>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9546666741371155\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9253333210945129, 'metrics/accuracy_top5': 0.984000027179718, 'fitness': 0.9546666741371155}\n",
       "save_dir: WindowsPath('runs/classify/RAdam_Aug_l')\n",
       "speed: {'preprocess': 0.04608099801199777, 'inference': 0.529939923967634, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9253333210945129\n",
       "top5: 0.984000027179718"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RAdam optimizer and default augmentations\n",
    "mymodel_RAdam_Aug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_RAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='RAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RAdam_Aug_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 29.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.925      0.984\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_l2\u001b[0m\n",
      "Top1 accuracy is 0.9250 and Top5 accuracy is 0.9840\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RAdam_Aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set of models with the following parameters:\n",
    "1. Automatic mixed precision\n",
    "2. Batch size of 32\n",
    "4. Manual augmentations (see specifics below)\n",
    "5. 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The default augmentations are:\n",
    "1. hsv_h=0.015- Controls the variation in hue.\n",
    "2. hsv_s=0.7- Controls the variation in saturation. A higher value (0.7) allows for a broader range of saturation changes.\n",
    "3. hsv_v=0.4- Controls the variation in value (brightness). A value of 0.4 allows moderate changes in brightness.\n",
    "4. translate=0.1- The range for random translation as a fraction of the image size. A value of 0.1 allows for slight shifts.\n",
    "5. scale=0.5- The range for random scaling. A value of 0.5 indicates a possibility of significant scaling.\n",
    "6. fliplr=0.5- Probability of flipping the image left to right.\n",
    "7. erasing=0.0- Probability of random erasing parts of the image.\n",
    "8. degrees=45- The range for random rotation.\n",
    "9. perspective=0.3- he range for random perspective transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=SGD_Aug_no_erasing3, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\SGD_Aug_no_erasing3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\SGD_Aug_no_erasing3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.37G      5.274         27        224: 100%|██████████| 2645/2645 [03:03<00:00, 14.43it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.634      0.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      3.41G      1.333         27        224: 100%|██████████| 2645/2645 [02:51<00:00, 15.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.914      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10       3.4G     0.5289         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.59it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.947      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      3.44G     0.3455         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.963      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10       3.4G     0.2325         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.57it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.971      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      3.44G     0.1674         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.979      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      3.41G     0.1269         27        224: 100%|██████████| 2645/2645 [02:38<00:00, 16.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.98      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.45G    0.09786         27        224: 100%|██████████| 2645/2645 [02:38<00:00, 16.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.978      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      3.41G    0.07701         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.61it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.982      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.44G    0.06282         27        224: 100%|██████████| 2645/2645 [02:38<00:00, 16.66it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.981      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.467 hours.\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug_no_erasing3\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug_no_erasing3\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\SGD_Aug_no_erasing3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 27.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.982      0.998\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_no_erasing3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_no_erasing3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E19E791280>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.990285724401474\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9820952415466309, 'metrics/accuracy_top5': 0.9984762072563171, 'fitness': 0.990285724401474}\n",
       "save_dir: WindowsPath('runs/classify/SGD_Aug_no_erasing3')\n",
       "speed: {'preprocess': 0.046473366873604906, 'inference': 0.5186768486386253, 'loss': 0.0003808339436848958, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9820952415466309\n",
       "top5: 0.9984762072563171"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with SGD optimizer and manual augmentations\n",
    "mymodel_SGD_Aug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_SGD_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='SGD',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='SGD_Aug_no_erasing_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 29.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.982      0.998\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_no_erasing32\u001b[0m\n",
      "Top1 accuracy is 0.9821 and Top5 accuracy is 0.9985\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_SGD_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_SGD_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=Adam_Aug_no_erasing_l2, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\Adam_Aug_no_erasing_l2\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\Adam_Aug_no_erasing_l2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.43G      3.039         27        224: 100%|██████████| 2645/2645 [03:12<00:00, 13.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.346      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10       3.5G      2.617         27        224: 100%|██████████| 2645/2645 [02:56<00:00, 14.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.677      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      3.48G      2.088         27        224: 100%|██████████| 2645/2645 [02:51<00:00, 15.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.733      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      3.59G      1.894         27        224: 100%|██████████| 2645/2645 [02:41<00:00, 16.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.829      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10       3.5G      1.672         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.854      0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      3.59G      1.475         27        224: 100%|██████████| 2645/2645 [02:41<00:00, 16.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.879      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      3.52G      1.279         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.24it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.89      0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.59G      1.092         27        224: 100%|██████████| 2645/2645 [02:43<00:00, 16.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.912      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10       3.5G     0.8891         27        224: 100%|██████████| 2645/2645 [02:44<00:00, 16.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.59G     0.6849         27        224: 100%|██████████| 2645/2645 [02:44<00:00, 16.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.482 hours.\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug_no_erasing_l2\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug_no_erasing_l2\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\Adam_Aug_no_erasing_l2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.984\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_no_erasing_l2\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_no_erasing_l2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E1B8F9DE80>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9573333263397217\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9302856922149658, 'metrics/accuracy_top5': 0.9843809604644775, 'fitness': 0.9573333263397217}\n",
       "save_dir: WindowsPath('runs/classify/Adam_Aug_no_erasing_l2')\n",
       "speed: {'preprocess': 0.054857889811197914, 'inference': 0.5415623074486142, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9302856922149658\n",
       "top5: 0.9843809604644775"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with Adam optimizer and manual augmentations\n",
    "mymodel_Adam_Aug = YOLO(\"yolov8l-cls.pt\")\n",
    "mymodel_Adam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='Adam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='Adam_Aug_no_erasing_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:03<00:00, 23.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.984\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_no_erasing_l22\u001b[0m\n",
      "Top1 accuracy is 0.9295 and Top5 accuracy is 0.9840\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_Adam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_Adam_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=AdamW_Aug_no_erasing_l, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\AdamW_Aug_no_erasing_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\AdamW_Aug_no_erasing_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.28G      2.376         27        224: 100%|██████████| 2645/2645 [03:12<00:00, 13.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.736      0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      3.47G      1.334         27        224: 100%|██████████| 2645/2645 [02:56<00:00, 14.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.873      0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10       3.5G      0.909         27        224: 100%|██████████| 2645/2645 [02:45<00:00, 15.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906      0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      3.59G     0.6724         27        224: 100%|██████████| 2645/2645 [02:44<00:00, 16.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10       3.5G     0.4858         27        224: 100%|██████████| 2645/2645 [02:43<00:00, 16.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.953      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10       3.6G     0.3727         27        224: 100%|██████████| 2645/2645 [02:44<00:00, 16.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.956      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      3.49G     0.2756         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.961      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.59G     0.1929         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.965      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      3.49G     0.1289         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.59G    0.07985         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.995\n",
      "\n",
      "10 epochs completed in 0.481 hours.\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug_no_erasing_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug_no_erasing_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\AdamW_Aug_no_erasing_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 25.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.995\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_no_erasing_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_no_erasing_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E1B68ACB50>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9819047749042511\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9691428542137146, 'metrics/accuracy_top5': 0.9946666955947876, 'fitness': 0.9819047749042511}\n",
       "save_dir: WindowsPath('runs/classify/AdamW_Aug_no_erasing_l')\n",
       "speed: {'preprocess': 0.04683621724446615, 'inference': 0.538858141217913, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9691428542137146\n",
       "top5: 0.9946666955947876"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with AdamW optimizer and manual augmentations\n",
    "mymodel_AdamW_Aug = YOLO(\"yolov8l-cls.pt\").to(device)\n",
    "mymodel_AdamW_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='AdamW',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='AdamW_Aug_no_erasing_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 30.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.995\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_no_erasing_l2\u001b[0m\n",
      "Top1 accuracy is 0.9691 and Top5 accuracy is 0.9950\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_AdamW_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_AdamW_Aug\n",
    "del metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSProp_Aug_no_erasing_l, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSProp_Aug_no_erasing_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSProp_Aug_no_erasing_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.33G      6.633         27        224: 100%|██████████| 2645/2645 [03:06<00:00, 14.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      3.58G      6.649         27        224: 100%|██████████| 2645/2645 [02:52<00:00, 15.34it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      3.58G      6.457         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10       3.6G      6.336         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.61it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      3.57G      6.332         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      3.69G      6.317         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.57it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      3.59G      6.304         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.62G      6.294         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      3.57G      6.282         27        224: 100%|██████████| 2645/2645 [02:39<00:00, 16.59it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.61G      6.272         27        224: 100%|██████████| 2645/2645 [02:40<00:00, 16.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.470 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug_no_erasing_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug_no_erasing_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\RMSProp_Aug_no_erasing_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug_no_erasing_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug_no_erasing_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E1921E35B0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.00571428588591516\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.0019047618843615055, 'metrics/accuracy_top5': 0.009523809887468815, 'fitness': 0.00571428588591516}\n",
       "save_dir: WindowsPath('runs/classify/RMSProp_Aug_no_erasing_l')\n",
       "speed: {'preprocess': 0.046861012776692704, 'inference': 0.5339548020135788, 'loss': 0.0, 'postprocess': 0.0007371448335193452}\n",
       "task: 'classify'\n",
       "top1: 0.0019047618843615055\n",
       "top5: 0.009523809887468815"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and manual augmentations\n",
    "mymodel_RMSprop_Aug = YOLO(\"yolov8l-cls.pt\").to(device)\n",
    "mymodel_RMSprop_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSProp_Aug_no_erasing_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 29.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug_no_erasing_l2\u001b[0m\n",
      "Top1 accuracy is 0.0019 and Top5 accuracy is 0.0095\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RMSprop_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RMSprop_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=NAdam_Aug_no_erasing_l, exist_ok=False, pretrained=True, optimizer=NAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\NAdam_Aug_no_erasing_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m NAdam(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\NAdam_Aug_no_erasing_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.39G      2.702         27        224: 100%|██████████| 2645/2645 [03:15<00:00, 13.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.508      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10       3.5G      2.276         27        224: 100%|██████████| 2645/2645 [03:02<00:00, 14.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.758      0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10       3.5G      1.837         27        224: 100%|██████████| 2645/2645 [02:47<00:00, 15.82it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.77      0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10       3.6G      1.695         27        224: 100%|██████████| 2645/2645 [02:47<00:00, 15.83it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.842      0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      3.49G      1.511         27        224: 100%|██████████| 2645/2645 [02:48<00:00, 15.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.869      0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10       3.6G      1.344         27        224: 100%|██████████| 2645/2645 [02:47<00:00, 15.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.888      0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      3.49G      1.178         27        224: 100%|██████████| 2645/2645 [02:47<00:00, 15.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.91      0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.61G      1.012         27        224: 100%|██████████| 2645/2645 [02:48<00:00, 15.67it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 28.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.921      0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10       3.5G      0.828         27        224: 100%|██████████| 2645/2645 [02:46<00:00, 15.90it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.931      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.61G     0.6318         27        224: 100%|██████████| 2645/2645 [02:47<00:00, 15.82it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.939      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.493 hours.\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug_no_erasing_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug_no_erasing_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\NAdam_Aug_no_erasing_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 26.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.939      0.984\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_no_erasing_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_no_erasing_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E19C56C0D0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9613333344459534\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.939047634601593, 'metrics/accuracy_top5': 0.9836190342903137, 'fitness': 0.9613333344459534}\n",
       "save_dir: WindowsPath('runs/classify/NAdam_Aug_no_erasing_l')\n",
       "speed: {'preprocess': 0.044186183384486606, 'inference': 0.5144739605131603, 'loss': 0.0003810155959356399, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.939047634601593\n",
       "top5: 0.9836190342903137"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with NAdam optimizer and manual augmentations\n",
    "mymodel_NAdam_Aug = YOLO(\"yolov8l-cls.pt\").to(device)\n",
    "mymodel_NAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='NAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='NAdam_Aug_no_erasing_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 31.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.939      0.984\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_no_erasing_l2\u001b[0m\n",
      "Top1 accuracy is 0.9387 and Top5 accuracy is 0.9836\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_NAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_NAdam_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.77 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RAdam_Aug_no_erasing_l, exist_ok=False, pretrained=True, optimizer=RAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=45, translate=0.1, scale=0.5, shear=0.0, perspective=0.3, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RAdam_Aug_no_erasing_l\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1985805  ultralytics.nn.modules.head.Classify         [1024, 525]                   \n",
      "YOLOv8l-cls summary: 183 layers, 36,872,269 parameters, 36,872,269 gradients, 99.7 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RAdam(lr=0.01, momentum=0.937) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RAdam_Aug_no_erasing_l\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.45G      2.958         27        224: 100%|██████████| 2645/2645 [03:11<00:00, 13.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.323      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      3.56G       2.62         27        224: 100%|██████████| 2645/2645 [02:58<00:00, 14.82it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.672      0.872\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      3.57G      2.116         27        224: 100%|██████████| 2645/2645 [02:45<00:00, 15.96it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.755      0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      3.61G      1.923         27        224: 100%|██████████| 2645/2645 [02:45<00:00, 15.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.814      0.939\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      3.56G      1.678         27        224: 100%|██████████| 2645/2645 [02:45<00:00, 16.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.854      0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      3.59G      1.479         27        224: 100%|██████████| 2645/2645 [02:43<00:00, 16.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.872      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      3.57G      1.281         27        224: 100%|██████████| 2645/2645 [02:42<00:00, 16.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 30.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.902      0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      3.59G      1.087         27        224: 100%|██████████| 2645/2645 [02:43<00:00, 16.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.914      0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      3.57G     0.8828         27        224: 100%|██████████| 2645/2645 [02:48<00:00, 15.66it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      3.59G     0.6761         27        224: 100%|██████████| 2645/2645 [02:48<00:00, 15.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 29.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.486 hours.\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug_no_erasing_l\\weights\\last.pt, 73.9MB\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug_no_erasing_l\\weights\\best.pt, 73.9MB\n",
      "\n",
      "Validating runs\\classify\\RAdam_Aug_no_erasing_l\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 26.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.985\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_no_erasing_l\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_no_erasing_l\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E19C4D6AF0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9573333263397217\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9299047589302063, 'metrics/accuracy_top5': 0.9847618937492371, 'fitness': 0.9573333263397217}\n",
       "save_dir: WindowsPath('runs/classify/RAdam_Aug_no_erasing_l')\n",
       "speed: {'preprocess': 0.04723367236909412, 'inference': 0.5102093106224423, 'loss': 0.0003811972481863839, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9299047589302063\n",
       "top5: 0.9847618937492371"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RAdam optimizer and manual augmentations\n",
    "mymodel_RAdam_Aug = YOLO(\"yolov8l-cls.pt\").to(device)\n",
    "mymodel_RAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.0,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    degrees=45,\n",
    "    erasing=0.0,\n",
    "    scale=0.5,\n",
    "    perspective=0.3,\n",
    "    optimizer='RAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RAdam_Aug_no_erasing_l',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,857,101 parameters, 0 gradients, 99.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:02<00:00, 30.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.985\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_no_erasing_l2\u001b[0m\n",
      "Top1 accuracy is 0.9295 and Top5 accuracy is 0.9848\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RAdam_Aug"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPGINKQxVpQQf9gWtJTSZp1",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
