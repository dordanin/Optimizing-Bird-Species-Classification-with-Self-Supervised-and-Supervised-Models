{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5655,
     "status": "ok",
     "timestamp": 1722438208361,
     "user": {
      "displayName": "דור דנינו",
      "userId": "17259148283236873173"
     },
     "user_tz": -180
    },
    "id": "dD916Btcr3Sl",
    "outputId": "171236cb-5be3-4f57-bf99-23c52c9aad36"
   },
   "source": [
    "# Notebook for YOLOv8n-cls models with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5655,
     "status": "ok",
     "timestamp": 1722438208361,
     "user": {
      "displayName": "דור דנינו",
      "userId": "17259148283236873173"
     },
     "user_tz": -180
    },
    "id": "dD916Btcr3Sl",
    "outputId": "171236cb-5be3-4f57-bf99-23c52c9aad36"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set of models with the following parameters:\n",
    "1. Automatic mixed precision\n",
    "2. Batch size of 32\n",
    "4. No augmentations\n",
    "5. 10 epochs\n",
    "5. Dropout rate of 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErBvqpBYr9Yf",
    "outputId": "0b02831e-e56e-472b-b67a-8b9b7dfdad54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=SGD_noAug_dropout0.3, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\SGD_noAug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\SGD_noAug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.413G      4.946         27        224: 100%|██████████| 2645/2645 [00:44<00:00, 59.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 54.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.67      0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      0.47G       1.33         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 55.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.896      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.447G     0.6519         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 70.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.934      0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.455G     0.4599         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.66it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.954      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.447G     0.2917         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.963      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.455G     0.1999         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.965      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.447G     0.1358         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.455G    0.09247         27        224: 100%|██████████| 2645/2645 [00:36<00:00, 71.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 55.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.972      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.449G    0.06213         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 53.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.971      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.455G    0.04764         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 67.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.973      0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.118 hours.\n",
      "Optimizer stripped from runs\\classify\\SGD_noAug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\SGD_noAug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\SGD_noAug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 50.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.973      0.996\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_noAug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_noAug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD85F0DB20>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9845714271068573\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9729523658752441, 'metrics/accuracy_top5': 0.9961904883384705, 'fitness': 0.9845714271068573}\n",
       "save_dir: WindowsPath('runs/classify/SGD_noAug_dropout0.3')\n",
       "speed: {'preprocess': 0.09028080531529019, 'inference': 0.09308270045689174, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9729523658752441\n",
       "top5: 0.9961904883384705"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with SGD optimizer and no augmentations\n",
    "mymodel_SGD_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_SGD_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='SGD',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    name='SGD_noAug_dropout0.3',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "error",
     "timestamp": 1722429687601,
     "user": {
      "displayName": "דור דנינו",
      "userId": "17259148283236873173"
     },
     "user_tz": -180
    },
    "id": "q_BqhL_5sCXf",
    "outputId": "f91a0446-c12f-417b-f699-c1b630d13030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 73.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.973      0.996\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_noAug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9730 and Top5 accuracy is 0.9962\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_SGD_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=Adam_noAug_dropout0.3, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\Adam_noAug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\Adam_noAug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.472G      2.446         27        224: 100%|██████████| 2645/2645 [00:46<00:00, 57.15it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 55.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.608      0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.497G      1.801         27        224: 100%|██████████| 2645/2645 [00:41<00:00, 63.08it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 55.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.786      0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.497G      1.527         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.807      0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.516G      1.434         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 67.90it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.862      0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.497G      1.293         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 70.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.894      0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.516G      1.138         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 71.38it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.915      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.497G     0.9744         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 69.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.516G     0.8172         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 70.87it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.937      0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.497G     0.6285         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 70.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.943       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.516G     0.4316         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.951       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.119 hours.\n",
      "Optimizer stripped from runs\\classify\\Adam_noAug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\Adam_noAug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\Adam_noAug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.951       0.99\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_noAug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_noAug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD8E41C700>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9706666767597198\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9512380957603455, 'metrics/accuracy_top5': 0.9900952577590942, 'fitness': 0.9706666767597198}\n",
       "save_dir: WindowsPath('runs/classify/Adam_noAug_dropout0.3')\n",
       "speed: {'preprocess': 0.0750508081345331, 'inference': 0.09017081487746466, 'loss': 0.000381288074311756, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9512380957603455\n",
       "top5: 0.9900952577590942"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with Adam optimizer and no augmentations\n",
    "mymodel_Adam_noAug_dropout = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_Adam_noAug_dropout.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='Adam',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='Adam_noAug_dropout0.3',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 74.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.951       0.99\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_noAug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9509 and Top5 accuracy is 0.9901\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_Adam_noAug_dropout.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_Adam_noAug_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=AdamW_noAug_dropout0.3, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\AdamW_noAug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\AdamW_noAug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.457G      2.226         27        224: 100%|██████████| 2645/2645 [00:45<00:00, 58.58it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.72      0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.493G      1.119         27        224: 100%|██████████| 2645/2645 [00:41<00:00, 64.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.871      0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.493G     0.7753         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 67.59it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906      0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.501G      0.554         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 67.83it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 51.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.934      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.493G     0.3823         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.946      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.501G     0.2667         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.964      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.493G     0.1774         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.964      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.501G     0.1043         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.493G    0.05355         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 67.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.968      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.501G    0.02556         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.120 hours.\n",
      "Optimizer stripped from runs\\classify\\AdamW_noAug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\AdamW_noAug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\AdamW_noAug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 53.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.994\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_noAug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_noAug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD8F5BD070>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9815238118171692\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9691428542137146, 'metrics/accuracy_top5': 0.9939047694206238, 'fitness': 0.9815238118171692}\n",
       "save_dir: WindowsPath('runs/classify/AdamW_noAug_dropout0.3')\n",
       "speed: {'preprocess': 0.08527801150367374, 'inference': 0.106479735601516, 'loss': 0.0, 'postprocess': 0.0003810155959356399}\n",
       "task: 'classify'\n",
       "top1: 0.9691428542137146\n",
       "top5: 0.9939047694206238"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with AdamW optimizer and no augmentations\n",
    "mymodel_AdamW_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_AdamW_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='AdamW',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='AdamW_noAug_dropout0.3',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 63.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.969      0.995\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_noAug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9688 and Top5 accuracy is 0.9947\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_AdamW_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_AdamW_noAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSprop_noAug_dropout0.3, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSprop_noAug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSprop_noAug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      0.48G      5.664         27        224: 100%|██████████| 2645/2645 [00:44<00:00, 59.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 62.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.474G      5.582         27        224: 100%|██████████| 2645/2645 [00:41<00:00, 63.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019     0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.451G      5.492         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 67.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 55.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00762     0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.476G      5.689         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00457     0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.451G      5.595         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0061     0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.476G      5.442         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00724     0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.451G      5.248         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 70.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0061     0.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.476G      5.021         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 70.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0152     0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.451G      4.744         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0133      0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.476G      4.329         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 67.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 55.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0149     0.0648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.119 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSprop_noAug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 54.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0149     0.0644\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD94497760>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.039619047194719315\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.01485714316368103, 'metrics/accuracy_top5': 0.0643809512257576, 'fitness': 0.039619047194719315}\n",
       "save_dir: WindowsPath('runs/classify/RMSprop_noAug_dropout0.3')\n",
       "speed: {'preprocess': 0.07867440723237537, 'inference': 0.08398610069638207, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.01485714316368103\n",
       "top5: 0.0643809512257576"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and no augmentations(starting learning rate = 0.01)\n",
    "mymodel_RMSprop_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_RMSprop_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSprop_noAug_dropout0.3'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RMSprop_noAug_v2_dropout0.3, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.02, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSprop_noAug_v2_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.02, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSprop_noAug_v2_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.508G      6.233         27        224: 100%|██████████| 2645/2645 [00:47<00:00, 56.24it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00267     0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.531G      6.468         27        224: 100%|██████████| 2645/2645 [00:41<00:00, 63.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 52.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019     0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.497G      6.439         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      0.51G      6.453         27        224: 100%|██████████| 2645/2645 [00:37<00:00, 70.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.497G      6.419         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.14it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      0.51G      6.397         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.497G      6.359         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.61it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      0.51G       6.33         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.497G      6.306         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 68.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.512G      6.284         27        224: 100%|██████████| 2645/2645 [00:38<00:00, 69.02it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 60.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.122 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_v2_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSprop_noAug_v2_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSprop_noAug_v2_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all    0.00267     0.0114\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_v2_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_v2_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD8E395A00>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.00704761897213757\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.0026666666381061077, 'metrics/accuracy_top5': 0.011428571306169033, 'fitness': 0.00704761897213757}\n",
       "save_dir: WindowsPath('runs/classify/RMSprop_noAug_v2_dropout0.3')\n",
       "speed: {'preprocess': 0.0811413356236049, 'inference': 0.07161712646484375, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.0026666666381061077\n",
       "top5: 0.011428571306169033"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and no augmentations(starting learning rate = 0.02)\n",
    "mymodel_RMSprop_noAug_v2 = model\n",
    "mymodel_RMSprop_noAug_v2.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    lr0=0.02,\n",
    "    lrf=0.01,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSprop_noAug_v2_dropout0.3'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 79.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0149     0.0655\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSprop_noAug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.0149 and Top5 accuracy is 0.0655\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RMSprop_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RMSprop_noAug\n",
    "del mymodel_RMSprop_noAug_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=NAdam_noAug_dropout0.3, exist_ok=False, pretrained=True, optimizer=NAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\NAdam_noAug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m NAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\NAdam_noAug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.495G      2.228         27        224: 100%|██████████| 2645/2645 [00:46<00:00, 56.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.684      0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.531G      1.602         27        224: 100%|██████████| 2645/2645 [00:42<00:00, 62.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.819      0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.531G      1.367         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 62.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.824      0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.549G      1.303         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 62.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.874       0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.533G      1.173         27        224: 100%|██████████| 2645/2645 [00:40<00:00, 66.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 62.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.898      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.552G       1.05         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.71it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.921      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.533G     0.9112         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.552G     0.7613         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.941       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.531G     0.5956         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.51it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 61.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.951       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.549G     0.4065         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.75it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.95       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.124 hours.\n",
      "Optimizer stripped from runs\\classify\\NAdam_noAug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\NAdam_noAug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\NAdam_noAug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 58.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.95       0.99\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_noAug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_noAug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD8600B4C0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9702857136726379\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9504761695861816, 'metrics/accuracy_top5': 0.9900952577590942, 'fitness': 0.9702857136726379}\n",
       "save_dir: WindowsPath('runs/classify/NAdam_noAug_dropout0.3')\n",
       "speed: {'preprocess': 0.07660048348563057, 'inference': 0.08492369878859747, 'loss': 0.0003809247698102678, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9504761695861816\n",
       "top5: 0.9900952577590942"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with NAdam optimizer and no augmentations\n",
    "mymodel_NAdam_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_NAdam_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='NAdam',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='NAdam_noAug_dropout0.3',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 76.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.95       0.99\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_noAug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9505 and Top5 accuracy is 0.9901\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_NAdam_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_NAdam_noAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=RAdam_noAug_dropout0.3, exist_ok=False, pretrained=True, optimizer=RAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RAdam_noAug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RAdam_noAug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.501G      2.557         27        224: 100%|██████████| 2645/2645 [00:45<00:00, 57.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.59      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.535G      1.779         27        224: 100%|██████████| 2645/2645 [00:42<00:00, 62.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.778      0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.533G      1.536         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 61.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.824      0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.543G      1.436         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 67.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.862      0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.533G      1.282         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 62.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.887      0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.541G      1.142         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 67.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.913      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.535G     0.9711         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 67.07it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 59.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.541G      0.811         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 67.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 62.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.938      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.533G     0.6194         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 66.95it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 61.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.947      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.541G      0.421         27        224: 100%|██████████| 2645/2645 [00:39<00:00, 67.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 62.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.952       0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.123 hours.\n",
      "Optimizer stripped from runs\\classify\\RAdam_noAug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RAdam_noAug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RAdam_noAug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 57.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.952       0.99\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_noAug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_noAug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD673EE070>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9710476100444794\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.951619029045105, 'metrics/accuracy_top5': 0.9904761910438538, 'fitness': 0.9710476100444794}\n",
       "save_dir: WindowsPath('runs/classify/RAdam_noAug_dropout0.3')\n",
       "speed: {'preprocess': 0.0731483641124907, 'inference': 0.08723876589820499, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.951619029045105\n",
       "top5: 0.9904761910438538"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RAdam optimizer and no augmentations\n",
    "mymodel_RAdam_noAug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_RAdam_noAug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=False,\n",
    "    optimizer='RAdam',\n",
    "    device=device,\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    hsv_v=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    degrees=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    erasing=0.0,\n",
    "    copy_paste=0.0,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RAdam_noAug_dropout0.3',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 72.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.951       0.99\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_noAug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9512 and Top5 accuracy is 0.9905\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RAdam_noAug.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RAdam_noAug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set of models with the following parameters:\n",
    "1. Automatic mixed precision\n",
    "2. Batch size of 32\n",
    "4. Default augmentations (see specifics below)\n",
    "5. 10 epochs\n",
    "5. Dropout rate of 0.3\n",
    "\n",
    "\n",
    "## The default augmentations are:\n",
    "1. hsv_h=0.015- Controls the variation in hue.\n",
    "2. hsv_s=0.7- Controls the variation in saturation. A higher value (0.7) allows for a broader range of saturation changes.\n",
    "3. hsv_v=0.4- Controls the variation in value (brightness). A value of 0.4 allows moderate changes in brightness.\n",
    "4. translate=0.1- The range for random translation as a fraction of the image size. A value of 0.1 allows for slight shifts.\n",
    "5. scale=0.5- The range for random scaling. A value of 0.5 indicates a possibility of significant scaling.\n",
    "6. fliplr=0.5- Probability of flipping the image left to right.\n",
    "7. erasing=0.4- Probability of random erasing parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=SGD_Aug_dropout0.3, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\SGD_Aug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\SGD_Aug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.505G      5.225         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 46.03it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.555      0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.505G      1.915         27        224: 100%|██████████| 2645/2645 [00:56<00:00, 46.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 51.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.834      0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.482G      1.124         27        224: 100%|██████████| 2645/2645 [00:56<00:00, 46.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 49.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.888      0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.505G     0.9106         27        224: 100%|██████████| 2645/2645 [00:55<00:00, 47.24it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 49.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.482G     0.7115         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 46.08it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 54.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.939      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.505G     0.5974         27        224: 100%|██████████| 2645/2645 [00:58<00:00, 45.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 49.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.95      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.482G     0.5057         27        224: 100%|██████████| 2645/2645 [00:58<00:00, 45.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 49.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.956      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.505G     0.4386         27        224: 100%|██████████| 2645/2645 [00:59<00:00, 44.63it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 51.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.957      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.482G     0.3743         27        224: 100%|██████████| 2645/2645 [00:58<00:00, 44.88it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 52.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.962      0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.505G     0.3295         27        224: 100%|██████████| 2645/2645 [00:58<00:00, 45.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.963      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.171 hours.\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\SGD_Aug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\SGD_Aug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.963      0.995\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD91175D90>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.978857159614563\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9626666903495789, 'metrics/accuracy_top5': 0.9950476288795471, 'fitness': 0.978857159614563}\n",
       "save_dir: WindowsPath('runs/classify/SGD_Aug_dropout0.3')\n",
       "speed: {'preprocess': 0.07810801551455543, 'inference': 0.07580293927873884, 'loss': 0.0003809247698102678, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9626666903495789\n",
       "top5: 0.9950476288795471"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with SGD optimizer and default augmentations\n",
    "mymodel_SGD_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_SGD_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='SGD',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='SGD_Aug_dropout0.3',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 68.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.963      0.995\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\SGD_Aug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9630 and Top5 accuracy is 0.9950\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_SGD_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_SGD_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=Adam_Aug_dropout0.3, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\Adam_Aug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\Adam_Aug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      0.51G      3.189         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 46.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 54.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.516      0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.549G      2.584         27        224: 100%|██████████| 2645/2645 [00:58<00:00, 45.23it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 53.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.704      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.524G      2.287         27        224: 100%|██████████| 2645/2645 [00:58<00:00, 45.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 52.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.745      0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.535G      2.162         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 46.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 54.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.803       0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.524G      1.986         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 45.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 50.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.848      0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.533G      1.801         27        224: 100%|██████████| 2645/2645 [00:59<00:00, 44.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 45.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.874      0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.524G      1.586         27        224: 100%|██████████| 2645/2645 [00:59<00:00, 44.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.888       0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.533G      1.395         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 46.19it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 50.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.908      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.524G      1.151         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 46.26it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 49.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.916      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.533G     0.9087         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 45.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 50.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.922      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.172 hours.\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\Adam_Aug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\Adam_Aug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 55.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.982\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD916263D0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9523809552192688\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9226666688919067, 'metrics/accuracy_top5': 0.9820952415466309, 'fitness': 0.9523809552192688}\n",
       "save_dir: WindowsPath('runs/classify/Adam_Aug_dropout0.3')\n",
       "speed: {'preprocess': 0.08304105486188616, 'inference': 0.07160940624418713, 'loss': 0.0003810155959356399, 'postprocess': 0.00038728259858630956}\n",
       "task: 'classify'\n",
       "top1: 0.9226666688919067\n",
       "top5: 0.9820952415466309"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with Adam optimizer and default augmentations\n",
    "mymodel_Adam_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_Adam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='Adam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='Adam_Aug_dropout0.3',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 69.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.922      0.982\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\Adam_Aug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9223 and Top5 accuracy is 0.9817\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_Adam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_Adam_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=cuda:0, workers=8, project=None, name=AdamW_Aug_dropout0.3, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\AdamW_Aug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\AdamW_Aug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.514G      2.935         27        224: 100%|██████████| 2645/2645 [00:56<00:00, 46.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 52.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.671      0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.493G       1.74         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 46.40it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 55.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.799      0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.491G      1.337         27        224: 100%|██████████| 2645/2645 [00:56<00:00, 46.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 51.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.869      0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.495G      1.068         27        224: 100%|██████████| 2645/2645 [00:56<00:00, 46.65it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 52.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906      0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.491G     0.8544         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 46.03it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 56.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.93      0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.493G     0.7079         27        224: 100%|██████████| 2645/2645 [00:56<00:00, 46.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 53.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.943      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.491G     0.5731         27        224: 100%|██████████| 2645/2645 [00:56<00:00, 46.54it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 47.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.949      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.493G      0.478         27        224: 100%|██████████| 2645/2645 [00:57<00:00, 46.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 53.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.953      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.491G     0.3798         27        224: 100%|██████████| 2645/2645 [00:56<00:00, 46.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 51.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.954      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.493G     0.3021         27        224: 100%|██████████| 2645/2645 [00:56<00:00, 46.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 49.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.957      0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.169 hours.\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\AdamW_Aug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\AdamW_Aug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 55.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.957      0.992\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002AD66215B80>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9748571515083313\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9573333263397217, 'metrics/accuracy_top5': 0.9923809766769409, 'fitness': 0.9748571515083313}\n",
       "save_dir: WindowsPath('runs/classify/AdamW_Aug_dropout0.3')\n",
       "speed: {'preprocess': 0.07999810718354725, 'inference': 0.07848013015020461, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9573333263397217\n",
       "top5: 0.9923809766769409"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with AdamW optimizer and default augmentations\n",
    "mymodel_AdamW_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_AdamW_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='AdamW',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='AdamW_Aug_dropout0.3',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 71.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.957      0.992\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\AdamW_Aug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9566 and Top5 accuracy is 0.9924\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_AdamW_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_AdamW_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.78 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=0, workers=8, project=None, name=RMSProp_Aug_dropout0.3, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RMSProp_Aug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RMSProp_Aug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.415G      6.447         27        224: 100%|██████████| 2645/2645 [01:47<00:00, 24.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019     0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.463G      6.455         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.61it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019     0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.461G      6.348         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      0.48G      6.272         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.463G      6.328         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.482G      6.322         27        224: 100%|██████████| 2645/2645 [01:41<00:00, 25.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.463G      6.307         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      0.48G      6.294         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.463G      6.282         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.83it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      0.48G      6.272         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019    0.00952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.298 hours.\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RMSProp_Aug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RMSProp_Aug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019     0.0118\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000021486054790>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.0068571430165320635\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.0019047618843615055, 'metrics/accuracy_top5': 0.011809524148702621, 'fitness': 0.0068571430165320635}\n",
       "save_dir: WindowsPath('runs/classify/RMSProp_Aug_dropout0.3')\n",
       "speed: {'preprocess': 0.1055226098923456, 'inference': 0.14361853826613652, 'loss': 0.0007614862351190476, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.0019047618843615055\n",
       "top5: 0.011809524148702621"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RMSProp optimizer and default augmentations\n",
    "mymodel_RMSprop_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_RMSprop_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='RMSProp',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RMSProp_Aug_dropout0.3',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 69.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0019     0.0118\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RMSProp_Aug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.0019 and Top5 accuracy is 0.0118\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RMSprop_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RMSprop_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.78 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=0, workers=8, project=None, name=NAdam_Aug_dropout0.3, exist_ok=False, pretrained=True, optimizer=NAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\NAdam_Aug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m NAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\NAdam_Aug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.419G       2.91         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.581      0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.484G      2.322         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.743      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.461G      2.063         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.775      0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.487G      1.986         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.816      0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.463G      1.826         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.857      0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.472G      1.672         27        224: 100%|██████████| 2645/2645 [01:23<00:00, 31.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.876      0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.461G      1.493         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.898      0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.487G      1.316         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.913      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.463G      1.095         27        224: 100%|██████████| 2645/2645 [01:37<00:00, 27.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.92       0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.472G     0.8597         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.292 hours.\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\NAdam_Aug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\NAdam_Aug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 44.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.983\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000021488DAFA00>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9554285705089569\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9279999732971191, 'metrics/accuracy_top5': 0.9828571677207947, 'fitness': 0.9554285705089569}\n",
       "save_dir: WindowsPath('runs/classify/NAdam_Aug_dropout0.3')\n",
       "speed: {'preprocess': 0.08988516671316965, 'inference': 0.1382862272716704, 'loss': 0.0003808339436848958, 'postprocess': 0.0003810155959356399}\n",
       "task: 'classify'\n",
       "top1: 0.9279999732971191\n",
       "top5: 0.9828571677207947"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with NAdam optimizer and default augmentations\n",
    "mymodel_NAdam_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_NAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='NAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='NAdam_Aug_dropout0.3',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 64.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928      0.983\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\NAdam_Aug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9280 and Top5 accuracy is 0.9832\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_NAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_NAdam_Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.78 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/User/Documents/Deep Learning/Project/datasets/images, epochs=10, time=None, patience=100, batch=32, imgsz=224, save=True, save_period=5, cache=False, device=0, workers=8, project=None, name=RAdam_Aug_dropout0.3, exist_ok=False, pretrained=True, optimizer=RAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=backbone, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=None, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\RAdam_Aug_dropout0.3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n",
      "Overriding model.yaml nc=1000 with nc=525\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1002765  ultralytics.nn.modules.head.Classify         [256, 525]                    \n",
      "YOLOv8n-cls summary: 99 layers, 2,110,813 parameters, 2,110,813 gradients, 3.9 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\deep_learn\\lib\\site-packages\\ultralytics\\engine\\trainer.py:269: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... 84635 images, 0 corrupt: 100%|██\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RAdam(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\RAdam_Aug_dropout0.3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.442G      3.173         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.25it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.523      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.461G      2.535         27        224: 100%|██████████| 2645/2645 [01:43<00:00, 25.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 36.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.705      0.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.438G      2.277         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.746      0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.463G      2.159         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 38.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.799      0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.438G      1.978         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 42.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.85      0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.463G      1.789         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.84it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 40.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.87       0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.438G       1.58         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 39.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.895      0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.463G      1.378         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 35.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.911       0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.438G      1.132         27        224: 100%|██████████| 2645/2645 [01:42<00:00, 25.75it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 37.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.918      0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.463G     0.8895         27        224: 100%|██████████| 2645/2645 [01:44<00:00, 25.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:01<00:00, 41.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.299 hours.\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug_dropout0.3\\weights\\last.pt, 4.3MB\n",
      "Optimizer stripped from runs\\classify\\RAdam_Aug_dropout0.3\\weights\\best.pt, 4.3MB\n",
      "\n",
      "Validating runs\\classify\\RAdam_Aug_dropout0.3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 42/42 [00:00<00:00, 42.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.983\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_dropout0.3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_dropout0.3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x00000214BDC4C7C0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9531428515911102\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9230476021766663, 'metrics/accuracy_top5': 0.9832381010055542, 'fitness': 0.9531428515911102}\n",
       "save_dir: WindowsPath('runs/classify/RAdam_Aug_dropout0.3')\n",
       "speed: {'preprocess': 0.09905115763346355, 'inference': 0.12494822910853794, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.9230476021766663\n",
       "top5: 0.9832381010055542"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with RAdam optimizer and default augmentations\n",
    "mymodel_RAdam_Aug = YOLO(\"yolov8n-cls.pt\")\n",
    "mymodel_RAdam_Aug.train(\n",
    "    data=\"../dataset\",\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    dropout=0.3,\n",
    "    plots=True,\n",
    "    auto_augment=None,\n",
    "    augment=True,\n",
    "    optimizer='RAdam',\n",
    "    device=device,\n",
    "    freeze='backbone',\n",
    "    exist_ok=True,\n",
    "    project='../models/YOLOv8/',\n",
    "    name='RAdam_Aug_dropout0.3',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.75  Python-3.8.18 torch-2.4.0 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 2,107,405 parameters, 0 gradients, 3.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\train... found 84635 images in 525 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... found 2625 images in 525 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\test... found 2625 images in 525 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Documents\\Deep Learning\\Project\\datasets\\images\\val... 2625 images, 0 corrupt: 100%|███████\u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 83/83 [00:01<00:00, 69.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.923      0.983\n",
      "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\RAdam_Aug_dropout0.32\u001b[0m\n",
      "Top1 accuracy is 0.9230 and Top5 accuracy is 0.9832\n"
     ]
    }
   ],
   "source": [
    "metrics = mymodel_RAdam_Aug.val(augment=False)  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy\n",
    "print(f\"Top1 accuracy is {metrics.top1:.4f} and Top5 accuracy is {metrics.top5:.4f}\")\n",
    "del mymodel_RAdam_Aug"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPGINKQxVpQQf9gWtJTSZp1",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
